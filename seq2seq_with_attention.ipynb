{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2Seq_with_attention.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihl1YwMaRRum",
        "colab_type": "text"
      },
      "source": [
        "# Sequence to Sequence attention model for machine translation\n",
        "\n",
        "This notebook trains a sequence to sequence (seq2seq) model with two different attentions implemented for Spanish to English translation.\n",
        "\n",
        "The codes are built on TensorFlow Core tutorials: https://www.tensorflow.org/tutorials/text/nmt_with_attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rfbpjs2fgzuT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f89f466e-bc54-42f6-cc5a-68e099255711"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOsMShvlg4ua",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "# Load data set\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDa3tH1hRyNq",
        "colab_type": "text"
      },
      "source": [
        "*   Clean the sentences by removing special characters.\n",
        "*   Add a start and end token to each sentence.\n",
        "*   Create a word index and reverse word index (dictionaries mapping from word → id and id → word).\n",
        "*   Pad each sentence to a maximum length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwlD7yEZhM72",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download the file\n",
        "path_to_zip = tf.keras.utils.get_file(\n",
        "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
        "    extract=True)\n",
        "\n",
        "path_to_file = os.path.dirname(path_to_zip)+\"/spa-eng/spa.txt\""
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKjEWl6WhZyk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converts the unicode file to ascii\n",
        "def unicode_to_ascii(s):\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "      if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "  w = unicode_to_ascii(w.lower().strip())\n",
        "\n",
        "  # creating a space between a word and the punctuation following it\n",
        "  # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "  # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
        "  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "  w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\",\"¿\")\n",
        "  w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "\n",
        "  # remove extra space\n",
        "  w = w.strip()\n",
        "\n",
        "  # adding a start and an end token to the sentence\n",
        "  # so that the model know when to start and stop predicting.\n",
        "  w = '<start> ' + w + ' <end>'\n",
        "  return w"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xc58-K0XhdCM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "174ba80a-adab-4c0b-f7f9-a87f35d466b9"
      },
      "source": [
        "en_sentence = u\"May I borrow this @ book?\"\n",
        "sp_sentence = u\"¿Puedo tomar prestado este libro?\"\n",
        "print(preprocess_sentence(en_sentence))\n",
        "print(preprocess_sentence(sp_sentence))\n",
        "print(preprocess_sentence(sp_sentence).encode(\"UTF-8\"))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> may i borrow this book ? <end>\n",
            "<start> ¿ puedo tomar prestado este libro ? <end>\n",
            "b'<start> \\xc2\\xbf puedo tomar prestado este libro ? <end>'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Hw9ct4OhsRA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "cbd84acb-5fe2-4d85-b547-2cfa844e1d25"
      },
      "source": [
        "# Return word pairs in the format: [ENGLISH, SPANISH]\n",
        "def create_dataset(path, num_examples):\n",
        "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
        "  return zip(*word_pairs)\n",
        "\n",
        "en, sp = create_dataset(path_to_file, None)\n",
        "print(en[-1])\n",
        "print(sp[-1])\n",
        "print(len(en), len(sp))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> if you want to sound like a native speaker , you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo . <end>\n",
            "<start> si quieres sonar como un hablante nativo , debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un musico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado . <end>\n",
            "118964 118964\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCAYRuTlh5DY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tokenize the sentence into list of words(integers) and pad the sequence to the same length\n",
        "def tokenize(lang):\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "      filters='')\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "  return tensor, lang_tokenizer"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e13Aa8yliFkp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_dataset(path, num_examples=None):\n",
        "  # creating cleaned input, output pairs\n",
        "  targ_lang, inp_lang = create_dataset(path, num_examples)\n",
        "\n",
        "  input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
        "  target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
        "\n",
        "  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EasB_FLig5c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "edb4e941-3e42-4f4c-c050-6ff4c10554f3"
      },
      "source": [
        "# Try experimenting with the size of that dataset\n",
        "num_examples = 30000\n",
        "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
        "\n",
        "# Calculate max_length of the target tensors\n",
        "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n",
        "print(max_length_targ, max_length_inp)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11 16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oS6mqluirWG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "11df51bf-3ca9-4758-c8d2-ebaa16bad37b"
      },
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# Show length\n",
        "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))\n",
        "print(input_tensor_train[0])\n",
        "print(target_tensor_train[0])"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24000 24000 6000 6000\n",
            "[   1   17 4599   21  437    3    2    0    0    0    0    0    0    0\n",
            "    0    0]\n",
            "[   1    4   25 2964   79  482    3    2    0    0    0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4McPf16iuXH",
        "colab_type": "text"
      },
      "source": [
        "# Create a tf.data datasest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lckoCvxAjj3U",
        "colab_type": "text"
      },
      "source": [
        "The tf.data.Dataset API supports writing descriptive and efficient input pipelines. Dataset usage follows a common pattern:\n",
        "\n",
        "\n",
        "*   Create a source dataset from your input data.\n",
        "*   Apply dataset transformations to preprocess the data.\n",
        "*   Iterate over the dataset and process the elements.\n",
        "\n",
        "Iteration happens in a streaming fashion, so the full dataset does not need to fit into memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AK3NE1vUityv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "436b021b-fb2c-4947-ff9d-6a0e73cc165e"
      },
      "source": [
        "# Configuration \n",
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "steps_per_epoch_val = len(input_tensor_val)//BATCH_SIZE\n",
        "embedding_dim = 256  # for word embedding\n",
        "units = 1024  # dimensionality of the output space of RNN\n",
        "vocab_inp_size = len(inp_lang.word_index)+1\n",
        "vocab_tar_size = len(targ_lang.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "validation_dataset = tf.data.Dataset.from_tensor_slices((input_tensor_val, target_tensor_val)).shuffle(BUFFER_SIZE)\n",
        "validation_dataset = validation_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 16]), TensorShape([64, 11]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jzo3ZvYpv4KE",
        "colab_type": "text"
      },
      "source": [
        "# Basic seq2seq model: encoder and decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ex8ORksZcTbV",
        "colab_type": "text"
      },
      "source": [
        "Model groups layers into an object with training and inference features. Two ways to define tf model:\n",
        "\n",
        "![alt text](https://i.ibb.co/c8JX8Cc/tf-Model.jpg)\n",
        "\n",
        "Basic sequence to sequence model without attention:\n",
        "![alt text](https://i.ibb.co/QN0tyMp/seq2seq.jpg)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFjq9Ta3wA8F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True,  # Whether to return the last output in the output sequence, or the full sequence. \n",
        "                                   return_state=True,  # Whether to return the last state in addition to the output.\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4GoRSHSwScu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "88f891e9-382f-4be9-ec36-4ed733efb7c8"
      },
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# sample input\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 16, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sy6ualLHwYzY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # passing the concatenated vector to the GRU\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size, vocab)\n",
        "    x = self.fc(output)\n",
        "    return x, state"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUXzFdWhhu1D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "4317895b-4c82-4e8b-b871-b92d9ae1921b"
      },
      "source": [
        "tf.reshape([[1,2,3],[4,5,6]], (-1, 2))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
              "array([[1, 2],\n",
              "       [3, 4],\n",
              "       [5, 6]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_z9vs5U06hk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "da5eb030-be39-4f33-9ecc-d5b527220b81"
      },
      "source": [
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "sample_decoder_output, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
        "                                      sample_hidden, sample_output)\n",
        "\n",
        "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (64, 4935)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBGeYTE14Oij",
        "colab_type": "text"
      },
      "source": [
        "# Dot-product attention\n",
        "\n",
        "![alt text](https://i.ibb.co/TvhM1Z2/attention.jpg)\n",
        "\n",
        "![alt text](https://i.ibb.co/bvrcptV/dotproduct.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vqqDed3xYH-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DotProductAttention(tf.keras.layers.Layer):\n",
        "  def call(self, query, values):\n",
        "    # query hidden state shape == (batch_size, hidden size)\n",
        "    # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # values shape == (batch_size, max_len, hidden size)\n",
        "    # we are doing this to broadcast addition along the time axis to calculate the score\n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # inner product, score shape == (batch_size, max_length, 1)\n",
        "    score = query_with_time_axis * values\n",
        "    score = tf.reduce_sum(score, axis=2)\n",
        "    score = tf.expand_dims(score, 2)\n",
        "    \n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlQqI7zA2MTO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "571d9721-f930-4da9-e78f-bfae6ee8ecd7"
      },
      "source": [
        "attention_layer = DotProductAttention()\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention result shape: (batch size, units) (64, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (64, 16, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSWViCN635g8",
        "colab_type": "text"
      },
      "source": [
        "# Additive attention\n",
        "\n",
        "![alt text](https://i.ibb.co/BqDYNP1/additive.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1-eiiJ_xyoM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    # query hidden state shape == (batch_size, hidden size)\n",
        "    # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # values shape == (batch_size, max_len, hidden size)\n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # score shape == (batch_size, max_length, 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(values) + self.W2(query_with_time_axis)))\n",
        "\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cnv4ILg87cM",
        "colab_type": "text"
      },
      "source": [
        "# Decoder layer with attention\n",
        "\n",
        "![alt text](https://i.ibb.co/ZM25Zvv/Context-Vector.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXqWOEGh9BAm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DecoderWithAttention(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz, attention_layer = None):\n",
        "    super(DecoderWithAttention, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    # used for attention\n",
        "    self.attention = attention_layer\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "    attention_weights = None\n",
        "    \n",
        "    if self.attention:\n",
        "      # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "      context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "      # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "      x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # passing the concatenated vector to the GRU\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size, vocab)\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fK2x4JEx1Gji",
        "colab_type": "text"
      },
      "source": [
        "# Define loss function\n",
        "\n",
        "Cross-entropy loss, or log loss, measures the performance of a classification model whose output is a probability value between 0 and 1. Cross-entropy loss increases as the predicted probability diverges from the actual label. \n",
        "![alt text](https://i.ibb.co/GtD1vc9/cross-entropy.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9oozBiV1Khj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0)) \n",
        "  loss_ = loss_object(real, pred)\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFLLiTBgnwG-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d5b19fea-5bf4-4772-874d-868b7ca86dc6"
      },
      "source": [
        "print(loss_object([1,2],[[0,0.6,0.3,0.1],[0,0.6,0.3,0.1]]))\n",
        "print(loss_function([1,2],[[0,0.6,0.3,0.1],[0,0.6,0.3,0.1]]))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([1.063386  1.3633859], shape=(2,), dtype=float32)\n",
            "tf.Tensor(1.2133859, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2NpO5aG1UDu",
        "colab_type": "text"
      },
      "source": [
        "# Training\n",
        "\n",
        "@tf.function\n",
        "In TensorFlow 2, eager execution is turned on by default. The user interface is intuitive and flexible (running one-off operations is much easier and faster), but this can come at the expense of performance and deployability. It is recommended to debug in eager mode, then decorate with @tf.function for better performance.\n",
        "\n",
        "In TensorFlow 2.0, users should refactor their code into smaller functions which are called as needed. In general, it's not necessary to decorate each of these smaller functions with tf.function; only use tf.function to decorate high-level computations - for example, one step of training, or the forward pass of your model.\n",
        "\n",
        "TensorFlow provides the tf.GradientTape API for automatic differentiation; that is, computing the gradient of a computation with respect to some inputs, usually tf.Variables. TensorFlow \"records\" relevant operations executed inside the context of a tf.GradientTape onto a \"tape\". TensorFlow then uses that tape to compute the gradients of a \"recorded\" computation using reverse mode differentiation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mz6c3l931TC8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "def get_train_step_func():\n",
        "\n",
        "  @tf.function\n",
        "  def train_step(inp, targ, enc_hidden, encoder, decoder):\n",
        "    loss = 0\n",
        "\n",
        "    with tf.GradientTape() as tape: # for automatic differentiation\n",
        "      enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "      dec_hidden = enc_hidden\n",
        "\n",
        "      dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "      # Teacher forcing - feeding the target as the next input\n",
        "      for t in range(1, targ.shape[1]):\n",
        "        # passing enc_output to the decoder\n",
        "        predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "        loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "        # using teacher forcing\n",
        "        dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "    batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    return batch_loss\n",
        "    \n",
        "  return train_step\n",
        "    "
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zym-buZ_TEg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def caculate_validation_loss(inp, targ, enc_hidden, encoder, decoder):\n",
        "  loss = 0\n",
        "  enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "  # Teacher forcing - feeding the target as the next input\n",
        "  for t in range(1, targ.shape[1]):\n",
        "    predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "    loss += loss_function(targ[:, t], predictions)\n",
        "    dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  loss = loss / int(targ.shape[1])\n",
        "  return loss"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMo0_PVaJiP7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def training_seq2seq(epochs, attention):\n",
        "  encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "  decoder = DecoderWithAttention(vocab_tar_size, embedding_dim, units, BATCH_SIZE, attention)\n",
        "  train_step_func = get_train_step_func()\n",
        "  training_loss = []\n",
        "  validation_loss = []\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "    enc_hidden = encoder.initialize_hidden_state()\n",
        "    total_loss = 0\n",
        "\n",
        "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "      batch_loss = train_step_func(inp, targ, enc_hidden, encoder, decoder)\n",
        "      total_loss += batch_loss\n",
        "\n",
        "      if batch % 100 == 0:\n",
        "        print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch, batch_loss))\n",
        "        \n",
        "    enc_hidden = encoder.initialize_hidden_state()\n",
        "    total_val_loss = 0\n",
        "    for (batch, (inp, targ)) in enumerate(validation_dataset.take(steps_per_epoch)):\n",
        "      val_loss = caculate_validation_loss(inp, targ, enc_hidden, encoder, decoder)\n",
        "      total_val_loss += val_loss\n",
        "\n",
        "    training_loss.append(total_loss / steps_per_epoch)\n",
        "    validation_loss.append(total_val_loss / steps_per_epoch_val)\n",
        "    print('Epoch {} Loss {:.4f} Validation Loss {:.4f}'.format(epoch + 1,\n",
        "                                        training_loss[-1], validation_loss[-1]))\n",
        "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n",
        "  return encoder, decoder, training_loss, validation_loss"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r96cK-kAVLbG",
        "colab_type": "text"
      },
      "source": [
        "## Training seq2seq without attention\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4knY8jaQ1gcO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9e09c9ed-1014-4517-ee68-daafc57631cf"
      },
      "source": [
        "epochs = 10\n",
        "attention = None\n",
        "\n",
        "print(\"Running seq2seq model without attention\")\n",
        "encoder, decoder, training_loss, validation_loss = training_seq2seq(epochs, attention)\n",
        "\n",
        "tloss = training_loss\n",
        "vloss = validation_loss"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running seq2seq model without attention\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['encoder_2/embedding_4/embeddings:0', 'encoder_2/gru_4/gru_cell_4/kernel:0', 'encoder_2/gru_4/gru_cell_4/recurrent_kernel:0', 'encoder_2/gru_4/gru_cell_4/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['encoder_2/embedding_4/embeddings:0', 'encoder_2/gru_4/gru_cell_4/kernel:0', 'encoder_2/gru_4/gru_cell_4/recurrent_kernel:0', 'encoder_2/gru_4/gru_cell_4/bias:0'] when minimizing the loss.\n",
            "Epoch 1 Batch 0 Loss 4.7110\n",
            "Epoch 1 Batch 100 Loss 2.0786\n",
            "Epoch 1 Batch 200 Loss 2.1930\n",
            "Epoch 1 Batch 300 Loss 1.9326\n",
            "Epoch 1 Loss 2.2473 Validation Loss 1.8957\n",
            "Time taken for 1 epoch 46.64686298370361 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 1.8268\n",
            "Epoch 2 Batch 100 Loss 1.8045\n",
            "Epoch 2 Batch 200 Loss 1.7547\n",
            "Epoch 2 Batch 300 Loss 1.8610\n",
            "Epoch 2 Loss 1.8155 Validation Loss 1.8189\n",
            "Time taken for 1 epoch 37.74576234817505 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 1.6325\n",
            "Epoch 3 Batch 100 Loss 1.7577\n",
            "Epoch 3 Batch 200 Loss 1.6848\n",
            "Epoch 3 Batch 300 Loss 1.7930\n",
            "Epoch 3 Loss 1.7272 Validation Loss 1.7902\n",
            "Time taken for 1 epoch 37.687077045440674 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 1.6195\n",
            "Epoch 4 Batch 100 Loss 1.6738\n",
            "Epoch 4 Batch 200 Loss 1.5888\n",
            "Epoch 4 Batch 300 Loss 1.6157\n",
            "Epoch 4 Loss 1.6709 Validation Loss 1.7724\n",
            "Time taken for 1 epoch 37.562928676605225 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 1.6224\n",
            "Epoch 5 Batch 100 Loss 1.6429\n",
            "Epoch 5 Batch 200 Loss 1.6121\n",
            "Epoch 5 Batch 300 Loss 1.6698\n",
            "Epoch 5 Loss 1.6317 Validation Loss 1.7733\n",
            "Time taken for 1 epoch 37.40342473983765 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 1.5069\n",
            "Epoch 6 Batch 100 Loss 1.6403\n",
            "Epoch 6 Batch 200 Loss 1.6620\n",
            "Epoch 6 Batch 300 Loss 1.5749\n",
            "Epoch 6 Loss 1.6032 Validation Loss 1.7671\n",
            "Time taken for 1 epoch 37.366559743881226 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 1.5653\n",
            "Epoch 7 Batch 100 Loss 1.6324\n",
            "Epoch 7 Batch 200 Loss 1.5765\n",
            "Epoch 7 Batch 300 Loss 1.5979\n",
            "Epoch 7 Loss 1.5823 Validation Loss 1.7707\n",
            "Time taken for 1 epoch 37.954607009887695 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 1.4798\n",
            "Epoch 8 Batch 100 Loss 1.5567\n",
            "Epoch 8 Batch 200 Loss 1.5446\n",
            "Epoch 8 Batch 300 Loss 1.6297\n",
            "Epoch 8 Loss 1.5674 Validation Loss 1.7702\n",
            "Time taken for 1 epoch 37.80478286743164 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 1.5138\n",
            "Epoch 9 Batch 100 Loss 1.5070\n",
            "Epoch 9 Batch 200 Loss 1.5213\n",
            "Epoch 9 Batch 300 Loss 1.5852\n",
            "Epoch 9 Loss 1.5554 Validation Loss 1.7727\n",
            "Time taken for 1 epoch 37.5131299495697 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 1.5095\n",
            "Epoch 10 Batch 100 Loss 1.4057\n",
            "Epoch 10 Batch 200 Loss 1.5608\n",
            "Epoch 10 Batch 300 Loss 1.5752\n",
            "Epoch 10 Loss 1.5459 Validation Loss 1.7738\n",
            "Time taken for 1 epoch 37.584688663482666 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2w0wAvhVUtq",
        "colab_type": "text"
      },
      "source": [
        "## Training seq2seq with dot product attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alodSzmpX77O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cf08733c-02bb-4551-bded-c232f6d088ea"
      },
      "source": [
        "attention = DotProductAttention()\n",
        "print(\"Running seq2seq model with dot product attention\")\n",
        "encoder_dp, decoder_dp, training_loss, validation_loss = training_seq2seq(epochs, attention)\n",
        "\n",
        "tloss = np.vstack((tloss, training_loss))\n",
        "vloss = np.vstack((vloss, validation_loss))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running seq2seq model with dot product attention\n",
            "Epoch 1 Batch 0 Loss 4.5785\n",
            "Epoch 1 Batch 100 Loss 2.2091\n",
            "Epoch 1 Batch 200 Loss 1.7809\n",
            "Epoch 1 Batch 300 Loss 1.7467\n",
            "Epoch 1 Loss 2.0435 Validation Loss 1.6566\n",
            "Time taken for 1 epoch 77.14243030548096 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 1.5425\n",
            "Epoch 2 Batch 100 Loss 1.7227\n",
            "Epoch 2 Batch 200 Loss 1.5194\n",
            "Epoch 2 Batch 300 Loss 1.4029\n",
            "Epoch 2 Loss 1.4963 Validation Loss 1.4533\n",
            "Time taken for 1 epoch 66.64634156227112 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 1.3733\n",
            "Epoch 3 Batch 100 Loss 1.2843\n",
            "Epoch 3 Batch 200 Loss 1.2344\n",
            "Epoch 3 Batch 300 Loss 1.2070\n",
            "Epoch 3 Loss 1.2750 Validation Loss 1.3275\n",
            "Time taken for 1 epoch 66.95986986160278 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 1.1600\n",
            "Epoch 4 Batch 100 Loss 1.1896\n",
            "Epoch 4 Batch 200 Loss 1.0816\n",
            "Epoch 4 Batch 300 Loss 1.1080\n",
            "Epoch 4 Loss 1.1106 Validation Loss 1.2618\n",
            "Time taken for 1 epoch 66.60793089866638 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.9927\n",
            "Epoch 5 Batch 100 Loss 0.8858\n",
            "Epoch 5 Batch 200 Loss 0.9132\n",
            "Epoch 5 Batch 300 Loss 1.0444\n",
            "Epoch 5 Loss 0.9726 Validation Loss 1.1985\n",
            "Time taken for 1 epoch 66.4554181098938 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.8466\n",
            "Epoch 6 Batch 100 Loss 0.8973\n",
            "Epoch 6 Batch 200 Loss 0.7940\n",
            "Epoch 6 Batch 300 Loss 0.7665\n",
            "Epoch 6 Loss 0.8494 Validation Loss 1.1572\n",
            "Time taken for 1 epoch 66.53202247619629 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.7913\n",
            "Epoch 7 Batch 100 Loss 0.7380\n",
            "Epoch 7 Batch 200 Loss 0.7251\n",
            "Epoch 7 Batch 300 Loss 0.6861\n",
            "Epoch 7 Loss 0.7385 Validation Loss 1.1228\n",
            "Time taken for 1 epoch 66.46661710739136 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.5941\n",
            "Epoch 8 Batch 100 Loss 0.6583\n",
            "Epoch 8 Batch 200 Loss 0.6867\n",
            "Epoch 8 Batch 300 Loss 0.6311\n",
            "Epoch 8 Loss 0.6407 Validation Loss 1.0949\n",
            "Time taken for 1 epoch 66.77675795555115 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.5246\n",
            "Epoch 9 Batch 100 Loss 0.4972\n",
            "Epoch 9 Batch 200 Loss 0.5905\n",
            "Epoch 9 Batch 300 Loss 0.5149\n",
            "Epoch 9 Loss 0.5438 Validation Loss 1.0758\n",
            "Time taken for 1 epoch 66.6980881690979 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.4612\n",
            "Epoch 10 Batch 100 Loss 0.4374\n",
            "Epoch 10 Batch 200 Loss 0.4666\n",
            "Epoch 10 Batch 300 Loss 0.4005\n",
            "Epoch 10 Loss 0.4581 Validation Loss 1.0544\n",
            "Time taken for 1 epoch 67.1820080280304 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQKjqurFVY0u",
        "colab_type": "text"
      },
      "source": [
        "## Training seq2seq with Bahdanau attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TUKivtyYix6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "99b8c391-323d-4552-8cf6-20c065f22817"
      },
      "source": [
        "epochs = 10\n",
        "\n",
        "attention = BahdanauAttention(units)\n",
        "print(\"Running seq2seq model with Bahdanau attention\")\n",
        "encoder_bah, decoder_bah, training_loss, validation_loss = training_seq2seq(epochs, attention)\n",
        "\n",
        "tloss = np.vstack((tloss, training_loss))\n",
        "vloss = np.vstack((vloss, validation_loss))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running seq2seq model with Bahdanau attention\n",
            "Epoch 1 Batch 0 Loss 4.5543\n",
            "Epoch 1 Batch 100 Loss 2.1009\n",
            "Epoch 1 Batch 200 Loss 1.8045\n",
            "Epoch 1 Batch 300 Loss 1.5984\n",
            "Epoch 1 Loss 1.9354 Validation Loss 1.5861\n",
            "Time taken for 1 epoch 94.48914361000061 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 1.4921\n",
            "Epoch 2 Batch 100 Loss 1.5060\n",
            "Epoch 2 Batch 200 Loss 1.3975\n",
            "Epoch 2 Batch 300 Loss 1.3689\n",
            "Epoch 2 Loss 1.4009 Validation Loss 1.3418\n",
            "Time taken for 1 epoch 83.52740979194641 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 1.1279\n",
            "Epoch 3 Batch 100 Loss 1.1811\n",
            "Epoch 3 Batch 200 Loss 1.0767\n",
            "Epoch 3 Batch 300 Loss 1.1381\n",
            "Epoch 3 Loss 1.1202 Validation Loss 1.1572\n",
            "Time taken for 1 epoch 83.03924703598022 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.9644\n",
            "Epoch 4 Batch 100 Loss 0.8292\n",
            "Epoch 4 Batch 200 Loss 0.8841\n",
            "Epoch 4 Batch 300 Loss 0.7663\n",
            "Epoch 4 Loss 0.8887 Validation Loss 1.0390\n",
            "Time taken for 1 epoch 83.87626075744629 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.7268\n",
            "Epoch 5 Batch 100 Loss 0.6574\n",
            "Epoch 5 Batch 200 Loss 0.6787\n",
            "Epoch 5 Batch 300 Loss 0.7390\n",
            "Epoch 5 Loss 0.6892 Validation Loss 0.9393\n",
            "Time taken for 1 epoch 83.8525083065033 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.5111\n",
            "Epoch 6 Batch 100 Loss 0.5136\n",
            "Epoch 6 Batch 200 Loss 0.5600\n",
            "Epoch 6 Batch 300 Loss 0.4396\n",
            "Epoch 6 Loss 0.5288 Validation Loss 0.8858\n",
            "Time taken for 1 epoch 83.91767573356628 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.3650\n",
            "Epoch 7 Batch 100 Loss 0.4099\n",
            "Epoch 7 Batch 200 Loss 0.3900\n",
            "Epoch 7 Batch 300 Loss 0.3447\n",
            "Epoch 7 Loss 0.4024 Validation Loss 0.8563\n",
            "Time taken for 1 epoch 83.46597647666931 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.2903\n",
            "Epoch 8 Batch 100 Loss 0.3013\n",
            "Epoch 8 Batch 200 Loss 0.3189\n",
            "Epoch 8 Batch 300 Loss 0.3201\n",
            "Epoch 8 Loss 0.3093 Validation Loss 0.8329\n",
            "Time taken for 1 epoch 84.20953631401062 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.2433\n",
            "Epoch 9 Batch 100 Loss 0.2097\n",
            "Epoch 9 Batch 200 Loss 0.2192\n",
            "Epoch 9 Batch 300 Loss 0.2974\n",
            "Epoch 9 Loss 0.2428 Validation Loss 0.8241\n",
            "Time taken for 1 epoch 83.42998266220093 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.2334\n",
            "Epoch 10 Batch 100 Loss 0.2025\n",
            "Epoch 10 Batch 200 Loss 0.1966\n",
            "Epoch 10 Batch 300 Loss 0.1864\n",
            "Epoch 10 Loss 0.1940 Validation Loss 0.8280\n",
            "Time taken for 1 epoch 83.51210641860962 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5Yk-AZ4h3Hb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "9fa20aa4-bc8c-409a-a81b-424cbf2e3791"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "ax = plt.subplot(111) \n",
        "t = np.arange(1, epochs+1)\n",
        "\n",
        "for i in range(0, vloss.shape[0]):\n",
        "  line, = plt.plot(t, vloss[i,:], lw=2)\n",
        "\n",
        "ax.legend(('No attention', 'Dot product', 'Bahdanau'))\n",
        "ax.set_title(\"Validation loss\")\n"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Validation loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBeMYwpMOPyI",
        "colab_type": "text"
      },
      "source": [
        "# Translation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ad9Fn5HrOO6i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def translate(sentence, encoder, decoder):\n",
        "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_length_inp,\n",
        "                                                         padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  result = ''\n",
        "\n",
        "  hidden = [tf.zeros((1, units))]\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "  for t in range(max_length_targ):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                         dec_hidden,\n",
        "                                                         enc_out)\n",
        "\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "    result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "    # until the predicted word is <end>.\n",
        "    if targ_lang.index_word[predicted_id] == '<end>':\n",
        "      return result, sentence\n",
        "\n",
        "    # the predicted ID is fed back into the model, no teacher forcing.\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  return result, sentence"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmPB_EoAWxKP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f78ae03d-0500-4a4e-df2e-ce55b368194e"
      },
      "source": [
        "result, sentence = translate(u'esta es mi vida.', encoder_bah, decoder_bah)\n",
        "print('Input: %s' % (sentence))\n",
        "print('Predicted translation: {}'.format(result))"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> esta es mi vida . <end>\n",
            "Predicted translation: this is my life . <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZWVIi421_4o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "87e28e16-0047-45a5-c6a7-636e94423b20"
      },
      "source": [
        "result, sentence = translate(u'esta es mi vida.', encoder_dp, decoder_dp)\n",
        "print('Input: %s' % (sentence))\n",
        "print('Predicted translation: {}'.format(result))"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> esta es mi vida . <end>\n",
            "Predicted translation: this is my office . <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrB48Fwk7XW8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "a2ce8cda-26ea-4fa5-f6e2-0f2a6a740fb7"
      },
      "source": [
        "result, sentence = translate(u'¿todavia estan en casa?', encoder_bah, decoder_bah)\n",
        "print('Input: %s' % (sentence))\n",
        "print('Predicted translation: {}'.format(result))"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> ¿ todavia estan en casa ? <end>\n",
            "Predicted translation: are you still at home ? <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLZcz8TbR09_",
        "colab_type": "text"
      },
      "source": [
        "# Next Steps\n",
        "\n",
        "\n",
        "*   Training on larger dataset\n",
        "*   Model tuning\n",
        "*   Try out other attention scores such as multiplicative\n",
        "*   Train on other seq2seq tasks\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}