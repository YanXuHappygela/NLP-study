{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2Seq_with_attention.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihl1YwMaRRum",
        "colab_type": "text"
      },
      "source": [
        "# Sequence to Sequence attention model for machine translation\n",
        "\n",
        "This notebook trains a sequence to sequence (seq2seq) model with two different attentions implemented for Spanish to English translation.\n",
        "\n",
        "The codes are built on TensorFlow Core tutorials: https://www.tensorflow.org/tutorials/text/nmt_with_attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rfbpjs2fgzuT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ac244187-d1ce-45ec-9745-aad0ce5441e2"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOsMShvlg4ua",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "# Load data set\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDa3tH1hRyNq",
        "colab_type": "text"
      },
      "source": [
        "*   Clean the sentences by removing special characters.\n",
        "*   Add a start and end token to each sentence.\n",
        "*   Create a word index and reverse word index (dictionaries mapping from word → id and id → word).\n",
        "*   Pad each sentence to a maximum length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwlD7yEZhM72",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download the file\n",
        "path_to_zip = tf.keras.utils.get_file(\n",
        "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
        "    extract=True)\n",
        "\n",
        "path_to_file = os.path.dirname(path_to_zip)+\"/spa-eng/spa.txt\""
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKjEWl6WhZyk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converts the unicode file to ascii\n",
        "def unicode_to_ascii(s):\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "      if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "  w = unicode_to_ascii(w.lower().strip())\n",
        "\n",
        "  # creating a space between a word and the punctuation following it\n",
        "  # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "  # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
        "  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "  w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\",\"¿\")\n",
        "  w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "\n",
        "  # remove extra space\n",
        "  w = w.strip()\n",
        "\n",
        "  # adding a start and an end token to the sentence\n",
        "  # so that the model know when to start and stop predicting.\n",
        "  w = '<start> ' + w + ' <end>'\n",
        "  return w"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xc58-K0XhdCM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "9adb75dc-9878-4834-edef-63cd720d181f"
      },
      "source": [
        "en_sentence = u\"May I borrow this @ book?\"\n",
        "sp_sentence = u\"¿Puedo tomar prestado este libro?\"\n",
        "print(preprocess_sentence(en_sentence))\n",
        "print(preprocess_sentence(sp_sentence))\n",
        "print(preprocess_sentence(sp_sentence).encode(\"UTF-8\"))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> may i borrow this book ? <end>\n",
            "<start> ¿ puedo tomar prestado este libro ? <end>\n",
            "b'<start> \\xc2\\xbf puedo tomar prestado este libro ? <end>'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Hw9ct4OhsRA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "7525f49f-0a47-4c5c-bc5a-0eaf0bbd2e02"
      },
      "source": [
        "# Return word pairs in the format: [ENGLISH, SPANISH]\n",
        "def create_dataset(path, num_examples):\n",
        "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
        "  return zip(*word_pairs)\n",
        "\n",
        "en, sp = create_dataset(path_to_file, None)\n",
        "print(en[-1])\n",
        "print(sp[-1])\n",
        "print(len(en), len(sp))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> if you want to sound like a native speaker , you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo . <end>\n",
            "<start> si quieres sonar como un hablante nativo , debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un musico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado . <end>\n",
            "118964 118964\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCAYRuTlh5DY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tokenize the sentence into list of words(integers) and pad the sequence to the same length\n",
        "def tokenize(lang):\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "      filters='')\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "  return tensor, lang_tokenizer"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e13Aa8yliFkp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_dataset(path, num_examples=None):\n",
        "  # creating cleaned input, output pairs\n",
        "  targ_lang, inp_lang = create_dataset(path, num_examples)\n",
        "\n",
        "  input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
        "  target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
        "\n",
        "  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EasB_FLig5c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "27af3380-a569-487b-b47e-11570c754f23"
      },
      "source": [
        "# Try experimenting with the size of that dataset\n",
        "num_examples = 30000\n",
        "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
        "\n",
        "# Calculate max_length of the target tensors\n",
        "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n",
        "print(max_length_targ, max_length_inp)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11 16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oS6mqluirWG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "e63733b7-b6d3-4f52-fc82-f68aca27671b"
      },
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# Show length\n",
        "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))\n",
        "print(input_tensor_train[0])\n",
        "print(target_tensor_train[0])"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24000 24000 6000 6000\n",
            "[  1 284  49 363  85   3   2   0   0   0   0   0   0   0   0   0]\n",
            "[  1  94  19 543  20   3   2   0   0   0   0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4McPf16iuXH",
        "colab_type": "text"
      },
      "source": [
        "# Create a tf.data datasest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lckoCvxAjj3U",
        "colab_type": "text"
      },
      "source": [
        "The tf.data.Dataset API supports writing descriptive and efficient input pipelines. Dataset usage follows a common pattern:\n",
        "\n",
        "\n",
        "*   Create a source dataset from your input data.\n",
        "*   Apply dataset transformations to preprocess the data.\n",
        "*   Iterate over the dataset and process the elements.\n",
        "\n",
        "Iteration happens in a streaming fashion, so the full dataset does not need to fit into memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AK3NE1vUityv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0bbd265c-d27f-4bda-cf08-eb85fcb9e16f"
      },
      "source": [
        "# Configuration \n",
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "embedding_dim = 256  # for word embedding\n",
        "units = 1024  # for GRU hidden state dimensions\n",
        "vocab_inp_size = len(inp_lang.word_index)+1\n",
        "vocab_tar_size = len(targ_lang.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "validation_dataset = tf.data.Dataset.from_tensor_slices((input_tensor_val, target_tensor_val)).shuffle(BUFFER_SIZE)\n",
        "validation_dataset = validation_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 16]), TensorShape([64, 11]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jzo3ZvYpv4KE",
        "colab_type": "text"
      },
      "source": [
        "# Basic seq2seq model: encoder and decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ex8ORksZcTbV",
        "colab_type": "text"
      },
      "source": [
        "Model groups layers into an object with training and inference features. Two ways to define tf model:\n",
        "\n",
        "![alt text](https://i.ibb.co/c8JX8Cc/tf-Model.jpg)\n",
        "\n",
        "Basic sequence to sequence model without attention:\n",
        "![alt text](https://i.ibb.co/QN0tyMp/seq2seq.jpg)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFjq9Ta3wA8F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True,  # Whether to return the last output in the output sequence, or the full sequence. \n",
        "                                   return_state=True,  # Whether to return the last state in addition to the output.\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4GoRSHSwScu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e63c06c0-116b-4c32-8fe5-8eda80706f63"
      },
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# sample input\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 16, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sy6ualLHwYzY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # passing the concatenated vector to the GRU\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size, vocab)\n",
        "    x = self.fc(output)\n",
        "    return x, state"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_z9vs5U06hk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9de3e5c9-e355-4794-cdce-4e7db38fa655"
      },
      "source": [
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "sample_decoder_output, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
        "                                      sample_hidden, sample_output)\n",
        "\n",
        "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (64, 4935)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBGeYTE14Oij",
        "colab_type": "text"
      },
      "source": [
        "# Dot-product attention\n",
        "\n",
        "![alt text](https://i.ibb.co/TvhM1Z2/attention.jpg)\n",
        "\n",
        "![alt text](https://i.ibb.co/bvrcptV/dotproduct.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vqqDed3xYH-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DotProductAttention(tf.keras.layers.Layer):\n",
        "  def call(self, query, values):\n",
        "    # query hidden state shape == (batch_size, hidden size)\n",
        "    # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # values shape == (batch_size, max_len, hidden size)\n",
        "    # we are doing this to broadcast addition along the time axis to calculate the score\n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # inner product, score shape == (batch_size, max_length)\n",
        "    score = query_with_time_axis * values\n",
        "    score = tf.reduce_sum(score, axis=2)\n",
        "    score = tf.expand_dims(score, 2)\n",
        "    \n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=0)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlQqI7zA2MTO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "3a960503-eb9a-415e-eacd-dcbf2703b265"
      },
      "source": [
        "attention_layer = DotProductAttention()\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention result shape: (batch size, units) (64, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (64, 16, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSWViCN635g8",
        "colab_type": "text"
      },
      "source": [
        "# Additive attention\n",
        "\n",
        "![alt text](https://i.ibb.co/BqDYNP1/additive.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1-eiiJ_xyoM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    # query hidden state shape == (batch_size, hidden size)\n",
        "    # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # values shape == (batch_size, max_len, hidden size)\n",
        "    # we are doing this to broadcast addition along the time axis to calculate the score\n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # score shape == (batch_size, max_length, 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(values) + self.W2(query_with_time_axis)))\n",
        "\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cnv4ILg87cM",
        "colab_type": "text"
      },
      "source": [
        "# Decoder layer with attention\n",
        "\n",
        "![alt text](https://i.ibb.co/ZM25Zvv/Context-Vector.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXqWOEGh9BAm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DecoderWithAttention(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz, attention_layer = None):\n",
        "    super(DecoderWithAttention, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    # used for attention\n",
        "    self.attention = attention_layer\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "    attention_weights = None\n",
        "    \n",
        "    if self.attention:\n",
        "      # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "      context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "      # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "      x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # passing the concatenated vector to the GRU\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size, vocab)\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fK2x4JEx1Gji",
        "colab_type": "text"
      },
      "source": [
        "# Define loss function\n",
        "\n",
        "Cross-entropy loss, or log loss, measures the performance of a classification model whose output is a probability value between 0 and 1. Cross-entropy loss increases as the predicted probability diverges from the actual label. \n",
        "![alt text](https://i.ibb.co/GtD1vc9/cross-entropy.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9oozBiV1Khj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0)) #convert 0, 1 to bool\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2NpO5aG1UDu",
        "colab_type": "text"
      },
      "source": [
        "# Training\n",
        "\n",
        "@tf.function\n",
        "In TensorFlow 2, eager execution is turned on by default. The user interface is intuitive and flexible (running one-off operations is much easier and faster), but this can come at the expense of performance and deployability. It is recommended to debug in eager mode, then decorate with @tf.function for better performance.\n",
        "\n",
        "In TensorFlow 2.0, users should refactor their code into smaller functions which are called as needed. In general, it's not necessary to decorate each of these smaller functions with tf.function; only use tf.function to decorate high-level computations - for example, one step of training, or the forward pass of your model.\n",
        "\n",
        "TensorFlow provides the tf.GradientTape API for automatic differentiation; that is, computing the gradient of a computation with respect to some inputs, usually tf.Variables. TensorFlow \"records\" relevant operations executed inside the context of a tf.GradientTape onto a \"tape\". TensorFlow then uses that tape to compute the gradients of a \"recorded\" computation using reverse mode differentiation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mz6c3l931TC8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "def get_train_step_func():\n",
        "\n",
        "  @tf.function\n",
        "  def train_step(inp, targ, enc_hidden, encoder, decoder):\n",
        "    loss = 0\n",
        "\n",
        "    with tf.GradientTape() as tape: # for automatic differentiation\n",
        "      enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "      dec_hidden = enc_hidden\n",
        "\n",
        "      dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "      # Teacher forcing - feeding the target as the next input\n",
        "      for t in range(1, targ.shape[1]):\n",
        "        # passing enc_output to the decoder\n",
        "        predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "        loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "        # using teacher forcing\n",
        "        dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "    batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    return batch_loss\n",
        "    \n",
        "  return train_step\n",
        "    "
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zym-buZ_TEg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def caculate_validation_loss(inp, targ, enc_hidden, encoder, decoder):\n",
        "  loss = 0\n",
        "  enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "  # Teacher forcing - feeding the target as the next input\n",
        "  for t in range(1, targ.shape[1]):\n",
        "    predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "    loss += loss_function(targ[:, t], predictions)\n",
        "    dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  loss = loss / int(targ.shape[1])\n",
        "  return loss"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMo0_PVaJiP7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def training_seq2seq(epochs, attention):\n",
        "  encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "  decoder = DecoderWithAttention(vocab_tar_size, embedding_dim, units, BATCH_SIZE, attention)\n",
        "  train_step_func = get_train_step_func()\n",
        "  training_loss = []\n",
        "  validation_loss = []\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "    enc_hidden = encoder.initialize_hidden_state()\n",
        "    total_loss = 0\n",
        "\n",
        "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "      batch_loss = train_step_func(inp, targ, enc_hidden, encoder, decoder)\n",
        "      total_loss += batch_loss\n",
        "\n",
        "      if batch % 100 == 0:\n",
        "        print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                    batch,\n",
        "                                                    batch_loss / int(targ.shape[0])))\n",
        "    enc_hidden = encoder.initialize_hidden_state()\n",
        "    total_val_loss = 0\n",
        "    for (batch, (inp, targ)) in enumerate(validation_dataset.take(steps_per_epoch)):\n",
        "      val_loss = caculate_validation_loss(inp, targ, enc_hidden, encoder, decoder)\n",
        "      total_val_loss += val_loss\n",
        "\n",
        "    training_loss.append(total_loss / len(input_tensor_train))\n",
        "    validation_loss.append(total_val_loss / len(input_tensor_val))\n",
        "    print('Epoch {} Loss {:.4f} Validation Loss {:.4f}'.format(epoch + 1,\n",
        "                                        training_loss[-1], validation_loss[-1]))\n",
        "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n",
        "  return encoder, decoder, training_loss, validation_loss"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r96cK-kAVLbG",
        "colab_type": "text"
      },
      "source": [
        "## Training seq2seq without attention\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4knY8jaQ1gcO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1a78b960-1faf-4539-d6b7-ff365a8e5320"
      },
      "source": [
        "epochs = 10\n",
        "attention = None\n",
        "\n",
        "print(\"Running seq2seq model without attention\")\n",
        "encoder, decoder, training_loss, validation_loss = training_seq2seq(epochs, attention)\n",
        "\n",
        "tloss = training_loss\n",
        "vloss = validation_loss"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running seq2seq model without attention\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['encoder_11/embedding_22/embeddings:0', 'encoder_11/gru_22/gru_cell_22/kernel:0', 'encoder_11/gru_22/gru_cell_22/recurrent_kernel:0', 'encoder_11/gru_22/gru_cell_22/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['encoder_11/embedding_22/embeddings:0', 'encoder_11/gru_22/gru_cell_22/kernel:0', 'encoder_11/gru_22/gru_cell_22/recurrent_kernel:0', 'encoder_11/gru_22/gru_cell_22/bias:0'] when minimizing the loss.\n",
            "Epoch 1 Batch 0 Loss 0.0715\n",
            "Epoch 1 Batch 100 Loss 0.0360\n",
            "Epoch 1 Batch 200 Loss 0.0326\n",
            "Epoch 1 Batch 300 Loss 0.0297\n",
            "Epoch 1 Loss 0.0351 Validation Loss 0.0295\n",
            "Time taken for 1 epoch 26.813003301620483 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 0.0288\n",
            "Epoch 2 Batch 100 Loss 0.0300\n",
            "Epoch 2 Batch 200 Loss 0.0288\n",
            "Epoch 2 Batch 300 Loss 0.0272\n",
            "Epoch 2 Loss 0.0284 Validation Loss 0.0283\n",
            "Time taken for 1 epoch 20.39032006263733 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 0.0269\n",
            "Epoch 3 Batch 100 Loss 0.0276\n",
            "Epoch 3 Batch 200 Loss 0.0269\n",
            "Epoch 3 Batch 300 Loss 0.0267\n",
            "Epoch 3 Loss 0.0270 Validation Loss 0.0278\n",
            "Time taken for 1 epoch 20.03193759918213 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.0266\n",
            "Epoch 4 Batch 100 Loss 0.0260\n",
            "Epoch 4 Batch 200 Loss 0.0281\n",
            "Epoch 4 Batch 300 Loss 0.0262\n",
            "Epoch 4 Loss 0.0261 Validation Loss 0.0277\n",
            "Time taken for 1 epoch 19.89475727081299 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.0246\n",
            "Epoch 5 Batch 100 Loss 0.0268\n",
            "Epoch 5 Batch 200 Loss 0.0255\n",
            "Epoch 5 Batch 300 Loss 0.0268\n",
            "Epoch 5 Loss 0.0255 Validation Loss 0.0276\n",
            "Time taken for 1 epoch 19.836297750473022 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.0249\n",
            "Epoch 6 Batch 100 Loss 0.0242\n",
            "Epoch 6 Batch 200 Loss 0.0260\n",
            "Epoch 6 Batch 300 Loss 0.0251\n",
            "Epoch 6 Loss 0.0250 Validation Loss 0.0275\n",
            "Time taken for 1 epoch 20.267353296279907 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.0232\n",
            "Epoch 7 Batch 100 Loss 0.0258\n",
            "Epoch 7 Batch 200 Loss 0.0244\n",
            "Epoch 7 Batch 300 Loss 0.0258\n",
            "Epoch 7 Loss 0.0247 Validation Loss 0.0276\n",
            "Time taken for 1 epoch 19.692211866378784 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.0242\n",
            "Epoch 8 Batch 100 Loss 0.0242\n",
            "Epoch 8 Batch 200 Loss 0.0249\n",
            "Epoch 8 Batch 300 Loss 0.0236\n",
            "Epoch 8 Loss 0.0245 Validation Loss 0.0276\n",
            "Time taken for 1 epoch 19.555434226989746 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.0229\n",
            "Epoch 9 Batch 100 Loss 0.0248\n",
            "Epoch 9 Batch 200 Loss 0.0258\n",
            "Epoch 9 Batch 300 Loss 0.0246\n",
            "Epoch 9 Loss 0.0243 Validation Loss 0.0276\n",
            "Time taken for 1 epoch 19.62995409965515 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.0234\n",
            "Epoch 10 Batch 100 Loss 0.0238\n",
            "Epoch 10 Batch 200 Loss 0.0242\n",
            "Epoch 10 Batch 300 Loss 0.0226\n",
            "Epoch 10 Loss 0.0241 Validation Loss 0.0277\n",
            "Time taken for 1 epoch 19.77085041999817 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2w0wAvhVUtq",
        "colab_type": "text"
      },
      "source": [
        "## Training seq2seq with dot product attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alodSzmpX77O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c04711b3-c642-4570-85ee-1daf10d02152"
      },
      "source": [
        "attention = DotProductAttention()\n",
        "print(\"Running seq2seq model with dot product attention\")\n",
        "encoder_dp, decoder_dp, training_loss, validation_loss = training_seq2seq(epochs, attention)\n",
        "\n",
        "tloss = np.vstack((tloss, training_loss))\n",
        "vloss = np.vstack((vloss, validation_loss))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running seq2seq model with dot product attention\n",
            "Epoch 1 Batch 0 Loss 0.0717\n",
            "Epoch 1 Batch 100 Loss 0.0308\n",
            "Epoch 1 Batch 200 Loss 0.0289\n",
            "Epoch 1 Batch 300 Loss 0.0258\n",
            "Epoch 1 Loss 0.0310 Validation Loss 0.0271\n",
            "Time taken for 1 epoch 42.122215270996094 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 0.0264\n",
            "Epoch 2 Batch 100 Loss 0.0247\n",
            "Epoch 2 Batch 200 Loss 0.0254\n",
            "Epoch 2 Batch 300 Loss 0.0246\n",
            "Epoch 2 Loss 0.0254 Validation Loss 0.0257\n",
            "Time taken for 1 epoch 34.2702202796936 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 0.0228\n",
            "Epoch 3 Batch 100 Loss 0.0238\n",
            "Epoch 3 Batch 200 Loss 0.0234\n",
            "Epoch 3 Batch 300 Loss 0.0234\n",
            "Epoch 3 Loss 0.0237 Validation Loss 0.0252\n",
            "Time taken for 1 epoch 34.64399003982544 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.0212\n",
            "Epoch 4 Batch 100 Loss 0.0230\n",
            "Epoch 4 Batch 200 Loss 0.0243\n",
            "Epoch 4 Batch 300 Loss 0.0216\n",
            "Epoch 4 Loss 0.0227 Validation Loss 0.0251\n",
            "Time taken for 1 epoch 34.40078353881836 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.0216\n",
            "Epoch 5 Batch 100 Loss 0.0228\n",
            "Epoch 5 Batch 200 Loss 0.0215\n",
            "Epoch 5 Batch 300 Loss 0.0220\n",
            "Epoch 5 Loss 0.0221 Validation Loss 0.0249\n",
            "Time taken for 1 epoch 34.23303699493408 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.0209\n",
            "Epoch 6 Batch 100 Loss 0.0216\n",
            "Epoch 6 Batch 200 Loss 0.0223\n",
            "Epoch 6 Batch 300 Loss 0.0213\n",
            "Epoch 6 Loss 0.0215 Validation Loss 0.0248\n",
            "Time taken for 1 epoch 34.14921283721924 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.0192\n",
            "Epoch 7 Batch 100 Loss 0.0219\n",
            "Epoch 7 Batch 200 Loss 0.0202\n",
            "Epoch 7 Batch 300 Loss 0.0207\n",
            "Epoch 7 Loss 0.0211 Validation Loss 0.0247\n",
            "Time taken for 1 epoch 34.31276798248291 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.0201\n",
            "Epoch 8 Batch 100 Loss 0.0206\n",
            "Epoch 8 Batch 200 Loss 0.0210\n",
            "Epoch 8 Batch 300 Loss 0.0218\n",
            "Epoch 8 Loss 0.0207 Validation Loss 0.0247\n",
            "Time taken for 1 epoch 33.895304441452026 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.0199\n",
            "Epoch 9 Batch 100 Loss 0.0209\n",
            "Epoch 9 Batch 200 Loss 0.0203\n",
            "Epoch 9 Batch 300 Loss 0.0209\n",
            "Epoch 9 Loss 0.0205 Validation Loss 0.0248\n",
            "Time taken for 1 epoch 33.83896231651306 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.0202\n",
            "Epoch 10 Batch 100 Loss 0.0203\n",
            "Epoch 10 Batch 200 Loss 0.0202\n",
            "Epoch 10 Batch 300 Loss 0.0195\n",
            "Epoch 10 Loss 0.0202 Validation Loss 0.0246\n",
            "Time taken for 1 epoch 34.148823499679565 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQKjqurFVY0u",
        "colab_type": "text"
      },
      "source": [
        "## Training seq2seq with Bahdanau attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TUKivtyYix6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f45c9957-18da-4cc8-9667-52a9c136ddf2"
      },
      "source": [
        "epochs = 10\n",
        "\n",
        "attention = BahdanauAttention(units)\n",
        "print(\"Running seq2seq model with Bahdanau attention\")\n",
        "encoder_bah, decoder_bah, training_loss, validation_loss = training_seq2seq(epochs, attention)\n",
        "\n",
        "tloss = np.vstack((tloss, training_loss))\n",
        "vloss = np.vstack((vloss, validation_loss))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running seq2seq model with Bahdanau attention\n",
            "Epoch 1 Batch 0 Loss 0.0732\n",
            "Epoch 1 Batch 100 Loss 0.0289\n",
            "Epoch 1 Batch 200 Loss 0.0259\n",
            "Epoch 1 Batch 300 Loss 0.0231\n",
            "Epoch 1 Loss 0.0285 Validation Loss 0.0231\n",
            "Time taken for 1 epoch 51.79730463027954 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 0.0204\n",
            "Epoch 2 Batch 100 Loss 0.0217\n",
            "Epoch 2 Batch 200 Loss 0.0203\n",
            "Epoch 2 Batch 300 Loss 0.0211\n",
            "Epoch 2 Loss 0.0206 Validation Loss 0.0203\n",
            "Time taken for 1 epoch 42.479480266571045 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 0.0179\n",
            "Epoch 3 Batch 100 Loss 0.0183\n",
            "Epoch 3 Batch 200 Loss 0.0154\n",
            "Epoch 3 Batch 300 Loss 0.0171\n",
            "Epoch 3 Loss 0.0169 Validation Loss 0.0184\n",
            "Time taken for 1 epoch 42.96311354637146 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.0133\n",
            "Epoch 4 Batch 100 Loss 0.0146\n",
            "Epoch 4 Batch 200 Loss 0.0133\n",
            "Epoch 4 Batch 300 Loss 0.0137\n",
            "Epoch 4 Loss 0.0137 Validation Loss 0.0169\n",
            "Time taken for 1 epoch 42.734049558639526 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.0104\n",
            "Epoch 5 Batch 100 Loss 0.0119\n",
            "Epoch 5 Batch 200 Loss 0.0116\n",
            "Epoch 5 Batch 300 Loss 0.0111\n",
            "Epoch 5 Loss 0.0109 Validation Loss 0.0159\n",
            "Time taken for 1 epoch 42.770267963409424 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.0090\n",
            "Epoch 6 Batch 100 Loss 0.0078\n",
            "Epoch 6 Batch 200 Loss 0.0076\n",
            "Epoch 6 Batch 300 Loss 0.0073\n",
            "Epoch 6 Loss 0.0084 Validation Loss 0.0152\n",
            "Time taken for 1 epoch 42.71212673187256 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.0062\n",
            "Epoch 7 Batch 100 Loss 0.0065\n",
            "Epoch 7 Batch 200 Loss 0.0061\n",
            "Epoch 7 Batch 300 Loss 0.0062\n",
            "Epoch 7 Loss 0.0063 Validation Loss 0.0147\n",
            "Time taken for 1 epoch 42.77549338340759 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.0045\n",
            "Epoch 8 Batch 100 Loss 0.0042\n",
            "Epoch 8 Batch 200 Loss 0.0046\n",
            "Epoch 8 Batch 300 Loss 0.0042\n",
            "Epoch 8 Loss 0.0045 Validation Loss 0.0146\n",
            "Time taken for 1 epoch 42.699928522109985 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.0029\n",
            "Epoch 9 Batch 100 Loss 0.0030\n",
            "Epoch 9 Batch 200 Loss 0.0028\n",
            "Epoch 9 Batch 300 Loss 0.0037\n",
            "Epoch 9 Loss 0.0033 Validation Loss 0.0146\n",
            "Time taken for 1 epoch 42.271891355514526 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.0022\n",
            "Epoch 10 Batch 100 Loss 0.0025\n",
            "Epoch 10 Batch 200 Loss 0.0032\n",
            "Epoch 10 Batch 300 Loss 0.0027\n",
            "Epoch 10 Loss 0.0024 Validation Loss 0.0146\n",
            "Time taken for 1 epoch 42.931692361831665 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5Yk-AZ4h3Hb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "64cfc7e3-9009-4f39-8085-4de3e0dc8b4a"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "ax = plt.subplot(111) \n",
        "t = np.arange(1, epochs+1)\n",
        "\n",
        "for i in range(0, vloss.shape[0]):\n",
        "  line, = plt.plot(t, vloss[i,:], lw=2)\n",
        "\n",
        "ax.legend(('No attention', 'Dot product', 'Bahdanau'))\n",
        "ax.set_title(\"Validation loss\")\n"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Validation loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEICAYAAABWJCMKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3xUVf7/8dcnk0pJgNAJ0kUDhGJgwYIowqoIKCCCBcv+xO6uddFVxK77XdeGDVdFWRVRRFEsqwIqikoQFOnFCKEmlIQWUubz++PeDJMhJEPapHyej8c87txzzz1zJsp9z23niqpijDGm9gkLdQeMMcaEhgWAMcbUUhYAxhhTS1kAGGNMLWUBYIwxtZQFgDHG1FIWAKbGEhEVkY7u+xdF5N5g6pbicy4Rkf+Vtp/FtDtARNLKu11jClgAmCpLRD4TkQeKKB8uIttEJDzYtlT1WlV9sBz61NYNC99nq+qbqjq4rG0bU9ksAExV9jpwqYhIQPllwJuqmheCPhlTY1gAmKrsAyAeOK2gQEQaAucBb4hIHxFZKCJ7RGSriEwWkciiGhKRqSLykN/8He46W0TkqoC6Q0RkiYhkicgmEZnkt/gbd7pHRPaJSD8RuUJEFvitf7KILBKRTHd6st+y+SLyoIh8JyJ7ReR/ItI4mD+GiJzorr9HRJaLyDC/ZeeKyAq3zc0icrtb3lhEPnbX2SUi34qI/bs3gAWAqcJU9SAwAxjnVzwaWKWqvwD5wC1AY6AfMBC4vqR2ReRs4HZgENAJOCugyn73MxsAQ4DrROR8d1l/d9pAVeup6sKAthsBc4BncMLr38AcEYn3q3YxcCXQFIh0+1JSnyOAj4D/uevdBLwpIp3dKq8A16hqfaArMNctvw1IA5oAzYC7ARv/xQAWAKbqex0YJSLR7vw4twxVXayqP6hqnqqmAi8BpwfR5mjgNVX9TVX3A5P8F6rqfFVdpqpeVf0VeDvIdsEJjLWqOs3t19vAKmCoX53XVHWNX8D1CKLdvkA94DFVzVHVucDHwFh3eS6QKCKxqrpbVX/2K28BtFHVXFX9Vm0AMOOyADBVmqouADKA80WkA9AHeAtARI53D29sE5Es4BGcvYGStAQ2+c3/4b9QRP4kIvNEJF1EMoFrg2y3oO0/Asr+AFr5zW/ze38AZ8MeVJ9V1XuUdkcC5wJ/iMjXItLPLf8/YB3wPxHZICITgvsapjawADDVwRs4v/wvBT5X1e1u+Qs4v647qWoszuGNwBPGRdkKtPabPy5g+VvAbKC1qsYBL/q1W9Kv5y1Am4Cy44DNQfSrpHZbBxy/97WrqotUdTjO4aEPcPYsUNW9qnqbqrYHhgG3isjAMvbF1BAWAKY6eAPnOP3VuId/XPWBLGCfiJwAXBdkezOAK0QkUUTqAPcFLK8P7FLVbBHpg3PMvkA64AXaH6XtT4DjReRiEQkXkYuARJzDNWXxI87ewp0iEiEiA3AOK00XkUj3XoQ4Vc3F+Zt4AUTkPBHp6F5JlYlz3sRb9EeY2sYCwFR57vH974G6OL/MC9yOs3HeC7wMvBNke58CT+GcKF3H4ROmBa4HHhCRvcBE3F/T7roHgIeB79wra/oGtL0T5yql24CdwJ3AeaqaEUzfiulzDs4G/xycQ2LPA+NUdZVb5TIg1T0Udi1wiVveCfgS2AcsBJ5X1Xll6YupOcTOBxljTO1kewDGGFNLWQAYY0wtZQFgjDG1lAWAMcbUUkGNpujeOv804AH+o6qPBSyPwrlU7yScKx8uUtVU9xK6KQXVgEmqOiuYNovSuHFjbdu2bTBdNsYY41q8eHGGqjYJLC/xKiAR8QBrcMZNSQMWAWNVdYVfneuBJFW9VkTGABeo6kXuNdY5qponIi2AX3DuaNSS2ixKcnKypqSkBP2ljTHGgIgsVtXkwPJgDgH1Adap6gb3WuTpwPCAOsM5fIPOe8BAERFVPeA3ZG80h++iDKZNY4wxFSiYAGhF4XFT0ig8rkmhOu4GPxNnJMSCcVWWA8uAa93lwbSJu/54EUkRkZT09PQgumuMMSYYFX4SWFV/VNUuQG/gLr9RHYNdf4qqJqtqcpMmRxzCMsYYU0rBBMBmCg+clcCRA1v56riPyovDORnso6orcW5H7xpkm8YYYypQMAGwCOgkIu3cpy2NofB4LLjzl7vvRwFzVVXddcIBRKQNcAKQGmSbxhhjKlCJl4G6V/DcCHyOc8nmq6q6XJyHdaeo6mycpxFNE5F1wC6cDTrAqcAEEcnFGYHw+oJBsYpqs5y/mzHGmGJUq8HgSnsZaL5X8YQFM0y8McbUPGW5DLRa83qVYZMX8I9Zy/hj5/5Qd8cYY6qMoO4Ers6Wpu1h+ZYslm/J4u2fNnJOtxZcd3oHuraKC3XXjDEmpGr8HkCv4xry5a39ufCkBDxhwpxft3Leswu47JUf+X5dBtXpEJgxxpSnWnEOoMDWzIO88u3vvPXTRg7k5AOQlBDHdad3YHCX5naewBhTIx3tHECtCoACew7kMG3hH0z9PpWd+3MAaNe4LuP7t2dEr1ZEhXvK/BnGGFNVWAAU4WBOPu8u3sSUbzaQtvsgAE3rR3HVqe245E/HUT86otw+yxhjQsUCoBh5+V7mLNvKC/PXs2rbXgDqR4dzad82XHlKW5rWP6bRK4wxpkqxAAiCqvL1mnRe/Ho9P2zYBUBkeBijTkpg/Gntadu4boV9tjHGVBQLgGO0ZONuXvx6Pf9bsR1VCBM4p2sLrj29A90S7BJSY0z1YQFQSut27GPKN+uZtWQzufnO3+rUjo25bkAHTu4Qj4hdOWSMqdosAMpoa+ZBXl3wO2/9uJH97iWk3VrFce3pHTi7q11CaoypuiwAyknmgVym/ZDKa98dvoS0bXwdxvfvwIherYiOsEtIjTFViwVAOcvOzefdlE1M+XYDm3Y5l5A2qR/FVae045K+xxFrl5AaY6oIC4AKkpfv5ZPftvHC/PWs3JoFQP2ocC7uexx/OaUdTWPtElJjTGhZAFQwVeWbtRm8MH/d4UtIPWGMPKkV4/t3oJ1dQmqMCRELgEq0dNMeXpy/ns9XbEMVROCcrs259vQOJCU0CHX3jDG1jAVACKxP38eUrzfw/pI03yWkxzWqQ2KLWE5sEUtiy1hObFGfVg1i7HJSY0yFsQAIoW2Z2bz6nXMJ6b5DeUcsj40O9wuEWBJbxNKpWT0blM4YUy7KFAAicjbwNM7ze/+jqo8FLI8C3gBOAnYCF6lqqogMAh4DIoEc4A5VneuuMxa4G1BgC3BpwfOCj6a6BkCB3Hwv69P3sXJrFiu2ZLFy615WbM1il3s5qb/wMKFj03q+QDixhbO3EF8vKgQ9N8ZUZ6UOABHxAGuAQUAasAgYq6or/OpcDySp6rUiMga4QFUvEpGewHZV3SIiXYHPVbWViITjbPQTVTVDRP4JHFDVScX1pboHQFFUlR17D7FiSxYrtjqvlVuz+D1jP0X9p2kWGxVwCCmWtvF17UY0Y8xRHS0AgnkkZB9gnapucBuaDgwHVvjVGQ5Mct+/B0wWEVHVJX51lgMx7t6CFxCgrojsBGKBdcf2lWoGEaFZbDTNYqM544SmvvIDOXms3rbXFwgrtmSxattetmcdYntWOvNWp/vqxkR46Ny8fqFDSCc0r0/dqBr/xE9jTBkEs4VoBWzym08D/nS0OqqaJyKZQDzgf0hnJPCzqh4CEJHrgGXAfmAtcENRHy4i44HxAMcdd1wQ3a0Z6kSG0/O4hvQ8rqGvzOtV/th1wO8QkrPHsDUzm6Wb9rB00x5fXRFoG1+XE1vUL7TH0Dw22k44G2OASnoovIh0AR4HBrvzEcB1QE9gA/AscBfwUOC6qjoFmALOIaDK6G9VFRYmtGtcl3aN63Jutxa+8t37c3xh4Owx7GXdjr38nrGf3zP288mybb66DepEcELz+jSuF0X96Ahio8OpHx3uvI8Jp35UROH56AjqRYXbISZjaqBgAmAz0NpvPsEtK6pOmnt8Pw7nZDAikgDMAsap6nq3fg+AgnkRmQFMKOV3qPUa1o3k5I6NObljY19ZTp6XdTv2FTqEtHJbFnsO5PpuVDsW9aKcoIiNLggIJxzqR4cTG+MXGtH+9Q7XrRsZTpiFiDFVSjABsAjoJCLtcDb0Y4CLA+rMBi4HFgKjgLmqqiLSAJgDTFDV7/zqbwYSRaSJqqbjnGBeWbavYvxFhoeR2NI57FNAVdmamc3aHfvYcyCHvdl5ZGXnsjc7j72+aR5ZBwPKDuWxz31tzcwuVX9EnCEyfKERHUG96HAiPEK4J4yIMHfqCXPKwtypR9yyMMJ9dcQ3H+EJI9ytHxnuTAPXKagTERZGRLh/287ySE+YhZNBVcn3KvnuNM+r5OcruV4vuflKXr479XrJzXPK8wrKvUpuntdZVkSd3HwveW6dXK+zTp5XyXHXceoU1Dv8eYfrKPeel0iP1uV7I2mJAeAe078R+BznMtBXVXW5iDwApKjqbOAVYJqIrAN24YQEwI1AR2CiiEx0ywa7VwXdD3wjIrnAH8AV5fnFzJFEhJYNYmjZIOaY1sv3KvsOFREShwrPZ/mFRmCwHMjJJys7j6zsI++DqAoiPEJUuIeo8DAiw8P8poXLosI9h99HhBHp8RAVUXz9qCDre0R8Gx9vwdTLEWWFlquS76XwclW83sPvVTmi3LdeQF2vV/EqKM56qorinH9SQBW87uVpBe8DywPrqlvZv92C9xTU8Ssr+Nx8v++b5y28US60kXY3oF71qxc47/UeuV6+O/X7nKps94EjLxcvK7sRzFSK3Hwv+wrCwg2FfYfyfL+enF9XhX/5+H4RFapTUOb3C8zrJSdP/X5JFawf2J738LpuWV6+kpPvDfWfx1QRYQLhYWF4woTwMCEsTA7vcbp7keG++YI916PscfrtzYZ7nD3NcE/hPdDg6jhtHd+0PnF1SjfKcFkuAzWmzCI8YTSsG0nDupGh7soRVJ0QOJTnJSfPmR7KzXfKcr2+6aG8/MPLC70/XBZs/ZyC+n6fme9VPGGCR4SwMNyp+JU5U09YwPKCMt8ywSMULpOjlB+xPoSJIOLsMQp+87hlAoIQJhyu55aJOBvRguUU0UbB4TanbuHl+L0v2ACHhwmesDB3evh15HzYEeXF1QnzW14wrW1XyFkAmFpPpODwjw29YWqXsFB3wBhjTGhYABhjTC1VOwLgxymw9ddQ98IYY6qUmn8OIH01fPZ3UC90Gw1n3gMN24S6V8YYE3I1fw+gbhP403XgiYRlM2ByMnx2Nxw49rthjTGmJqn5AVCnEZz9CNyYAkkXQX4u/PAcPN0dvn0Ccg6EuofGGBMSNT8ACjRsAyOmwDXfQIeBcCgLvnoAnu0Fi1+H/Kp5h6oxxlSU2hMABVokwWXvw7gPoUV32LsVProZXjwFVn1CkU9hMcaYGqj2BUCB9gPg6vkw8hVo0AbSV8H0sfDaObDxxxB3zhhjKl7tDQCAsDDoNso5P3D241AnHjYuhFcHw/RLIH1NqHtojDEVpnYHQIHwSOh7Ldy8FPrfARF1YNXH8Hxf+OivsHdbyW0YY0w1YwHgLzrWuU/g5iVw0pVO2eKp8ExP+OpByM4KafeMMaY8WQAUpX5zGPoU3PAjnDgUcg/At/+CZ3rADy9A3qFQ99AYY8rMAqA4jTvBRf+Fv3wBx/WDAzvhswkwuTf8+i54bRx5Y0z1ZQEQjNZ94MpPYex0aHIC7PkD3v9/8PIAWD8v1L0zxphSCSoARORsEVktIutE5IiHt4tIlIi84y7/UUTauuWDRGSxiCxzp2f6rRMpIlNEZI2IrBKRkeX1pSqECHQ+B679DoZNhvotYesvMO18mHaB894YY6qREgNARDzAc8A5QCIwVkQSA6r9Bditqh2BJ4HH3fIMYKiqdsN5aPw0v3X+AexQ1ePddr8uyxepNJ5w6HUZ3LQYBt4HUXGwfi681B9mXg27U0PdQ2OMCUowewB9gHWqukFVc4DpwPCAOsOB19337wEDRURUdYmqbnHLlwMxIhLlzl8FPAqgql5VzSjLF6l0kXXgtFvhr0uh341+g831hs/ugv07Q91DY4wpVjAB0ArY5Def5pYVWUdV84BMID6gzkjgZ1U9JCIN3LIHReRnEXlXRJoV9eEiMl5EUkQkJT09PYjuVrI6jeDPD7uDzY1xB5t73rliyAabM8ZUYZVyElhEuuAcFrrGLQoHEoDvVbUXsBD4V1HrquoUVU1W1eQmTZpURndLp2EbGPESXPstdDzLBpszxlR5wQTAZqC133yCW1ZkHREJB+KAne58AjALGKeq6936O4EDwPvu/LtAr1L0v+pp3g0unQnjZkOLHocHm3vhZFg1xwabM8ZUGcE8EWwR0ElE2uFs6McAFwfUmY1zknchMAqYq6rqHuqZA0xQ1e8KKrvLPgIGAHOBgcCKMn6XqqX96XD1PFgxy9kTyFgN0y92xhtqnuQERYvuzvv4DhDmCXWPjTG1jGgQv0hF5FzgKcADvKqqD4vIA0CKqs4WkWicK3x6AruAMaq6QUTuAe4C1vo1N1hVd4hIG3edBkA6cKWqbiyuH8nJyZqSknLs3zLU8nKcISW+fQL2FTGuUEQdaNbVDYUkJxSaJkJEdKV31RhT84jIYlVNPqI8mACoKqptABRQhcxNzgPqt/3qTpdBVtqRdcXj3HTmHwrNu0FMgyPrGmNMMSwAqrL9O51A2OYGwtZfYeda50H2gRq0KXz4qEUS1G/h3KhmjDFFsACobnIOwPblh4Nh66+wYwXkZR9Zt07jwnsKLbpDo/Z2XsEYAxw9AII5CWxCIbIOtO7tvArk50HGGmcvYduvzvAT236FAxmwYZ7zKhBRF5p18QuFJGhyop1XMMb42B5AdXcs5xXCwqFxZ2jeFWIaQUSMEzQRfq/IOk55RF13uTstWB4eZYebjKlmbA+gphKBBsc5rxPPO1x+tPMKO5Y7r1J/XphfYBQREIUCpbjlMRBZz7mTuk68896CxZhKZQFQU9WNhw5nOK8CBecV0lfCob3OfK7/6+CRZTluee5+Z5qfAzn7nFd58kQ6QVAn/nAo1Il3zm8cUea+7HCWMWViAVCbFHVe4Vjl5xUfEDnutMiygHVy9sKB3c6DdnL3O3dN790afF8i6hYdDnXjjwyLOvEQ0xA8EaX/7sbUMBYA5th4wsET6zw/uTzlHICDu5wwOLATDvi/33lk+f4MJzQy90NmsfcPFhYdV3Qw+A5P1T18mCqy7pHlkfXsXIipMSwATNUQ6W5o4xKCq6/qHMYqNiwClh3cBdmZzmvXhrL1V8JKDosiy+sG1CmibkSMhUtlys9z9kYPuYc2D+1zBnPM2ec8/7tOvPOc8PotnB8LNei/jQWAqZ5EnL2Q6Fho1C64dbz5zsY/MCQO7nEPTe33O0S1//D5kJx9fu/dOvk5zkYjZ2/FfL9CJ83rFj65XmRwxBQdOL4T8X5l4ZEV0+fKoupsmHPcDXVRG25f2V73fJd/WcA6eQeD/2xPJNRrDvWbQb1mTijUd6cF5fVbOFfZhVX9J+5aAJjaI8zjni9oBHQqW1v5eQEhsb+EEPFbXlKdvOzD50sq4nESYeFHCRP38l+P/2bB79duoV++RZUfS12/8iLrqvu32lf0Bt5bnsOrC0TVdw7vRdU7PI2Kdc4Z7c+Afdth7zbn8zM3lnzYMSzcLyiau3sQ7ss/KOo0DmlQWAAYUxqecPDEOecUypvX63fCPCAsfCfVAwPk4FECJ/CE/X5n43koy3lVV2ERzkY7qh5EutNCG/HAMr9lUfUPL4+s5+whBXtYJ+eAM6DjXve1b7t78YI7LQiK7D3OvThF3Y/jTzxQr6lfMBSERMDeRd0mFXJnvwWAMVVNWJi7oapXMe3n5fiFiX+IuFPNd+oVuknU731RN48GVbeE8sB2I2IKb8D9N+zhUYREZB1nmJVG7Yuvl3vwcBgUFxQHdwV39ZuEwUX/hROGlN93wQLAmNonPNJ5xTQMdU9qrogYaNjWeRUn75AbBv7B4AaF/57GgYwK+e9lAWCMMaESHnX4Tv7i5OU4ewHl/fHl3qIxxpjyVUFXblX965SMMcZUCAsAY4yppYIKABE5W0RWi8g6EZlQxPIoEXnHXf6jiLR1yweJyGIRWeZOzyxi3dki8ltZv4gxxphjU2IAiIgHeA44B0gExopIYkC1vwC7VbUj8CTwuFueAQxV1W7A5TgPgfdvewRQzsNKGmOMCUYwewB9gHWqukFVc4DpwPCAOsOB19337wEDRURUdYmqbnHLlwMxIhIFICL1gFuBh8r6JYwxxhy7YAKgFbDJbz7NLSuyjqrmAZlAfECdkcDPqnrInX8QeIISbnYXkfEikiIiKenp6UF01xhjTDAq5SSwiHTBOSx0jTvfA+igqrNKWldVp6hqsqomN2nSpIJ7aowxtUcw9wFsBlr7zSe4ZUXVSRORcCAO2AkgIgnALGCcqq536/cDkkUk1e1DUxGZr6oDSvk9jDEhlJubS1paGtnZ2aHuSq0WHR1NQkICERHBPfgomABYBHQSkXY4G/oxwMUBdWbjnORdCIwC5qqqikgDYA4wQVW/K6isqi8ALwC4Vwx9bBt/Y6qvtLQ06tevT9u2bZEaNF5+daKq7Ny5k7S0NNq1C26I9BIPAbnH9G8EPgdWAjNUdbmIPCAiw9xqrwDxIrIO58RuwaWiNwIdgYkistR9NT22r2WMqeqys7OJj4+3jX8IiQjx8fHHtBcW1FAQqvoJ8ElA2US/99nAhUWs9xAlXOWjqqlA12D6YYypumzjH3rH+t/A7gQ2xphaygLAGFMjiAi33Xabb/5f//oXkyZNKnO7S5cu5ZNPDh8AmT9/Pt9//32p29uzZw/PP/+8b37Lli2MGjWqTH0sLQsAY0yNEBUVxfvvv09GRka5tlvRAdCyZUvee++9MvWxtGpFAGQeyuRAbkU8XNUYU1WEh4czfvx4nnzyySOWpaamcuaZZ5KUlMTAgQPZuPHIZ/r+9NNP9OvXj549e3LyySezevVqcnJymDhxIu+88w49evTg8ccf58UXX+TJJ5+kR48efPvtt6SnpzNy5Eh69+5N7969+e4754LHSZMmcdVVVzFgwADat2/PM888A8CECRNYv349PXr04I477iA1NZWuXZ3ToNnZ2Vx55ZV069aNnj17Mm/ePACmTp3KiBEjOPvss+nUqRN33nln+fzNyqWVKmzb/m1c9+V1NK3TlMlnTibCE9z1scaY0mk7YU6FtJv6WMmPQ7zhhhtISko6YgN50003cfnll3P55Zfz6quvcvPNN/PBBx8UqnPCCSfw7bffEh4ezpdffsndd9/NzJkzeeCBB0hJSWHy5MkAHDx4kHr16nH77bcDcPHFF3PLLbdw6qmnsnHjRv785z+zcuVKAFatWsW8efPYu3cvnTt35rrrruOxxx7jt99+Y+nSpc73Sk319eG5555DRFi2bBmrVq1i8ODBrFmzBnD2RJYsWUJUVBSdO3fmpptuonVr/1u0jl2ND4BD+YfYlb2LdXvWcc939/DoaY8SVgFP1jHGhF5sbCzjxo3jmWeeISYmxle+cOFC3n//fQAuu+yyIn9BZ2Zmcvnll7N27VpEhNzc3KA+88svv2TFihW++aysLPbtc8a4HDJkCFFRUURFRdG0aVO2b99ebFsLFizgpptuApxAatOmjS8ABg4cSFxcHACJiYn88ccfFgAlaRPbhufPep6rPruKT37/hEbRjbiz9512yZoxFSSYX+oV6W9/+xu9evXiyiuvPKb17r33Xs444wxmzZpFamoqAwYMCGo9r9fLDz/8QHR09BHLoqIOP7ze4/GQl5d3TH2qqLYK1Iqfwl3iu/DUGU8RHhbOf1f+l9eWvxbqLhljKkijRo0YPXo0r7zyiq/s5JNPZvr06QC8+eabnHbaaUesl5mZSatWzjiXU6dO9ZXXr1+fvXv3HnV+8ODBPPvss775gkM7RxO4vr/TTjuNN998E4A1a9awceNGOnfuXGx7ZVErAgCgX8t+PHrqowjCk4uf5IN1H5S8kjGmWrrtttsKXQ307LPP8tprr5GUlMS0adN4+umnj1jnzjvv5K677qJnz56Ffl2fccYZrFixgh49evDOO+8wdOhQZs2a5TsJ/Mwzz5CSkkJSUhKJiYm8+OKLxfYtPj6eU045ha5du3LHHXcUWnb99dfj9Xrp1q0bF110EVOnTi30y7+8iapWWOPlLTk5WVNSUsrUxpsr3+Sxnx7DIx6ePuNpTm99ejn1zpjaa+XKlZx44omh7oah6P8WIrJYVZMD69aaPYACl5x4CVd3u5p8zef2r29n6Y7id9eMMaamqnUBAHBTz5sY2Wkk2fnZ3PDVDazbvS7UXTLGmEpXKwNARLin7z2c0foMsnKyuObLa9i6b2uou2WMMZWqVgYAQHhYOP/s/096Ne3FjgM7uObLa9iTvSfU3TLGmEpTawMAIDo8mmcHPkunhp34PfN3bvjqBhsywhhTa9TqAACIjYzlxbNepGXdlvya8Su3fX0bud7g7gA0xpjqrNYHAEDTOk15adBLNIxqyILNC7jvu/vwqjfU3TLGHAOPx0OPHj3o0qUL3bt354knnsDrLf7fceBInxXpiiuuKPWon4888kg598YRVACIyNkislpE1onIhCKWR4nIO+7yH93n/CIig0RksYgsc6dnuuV1RGSOiKwSkeUi8lh5fqnSaBvXlufPep6Y8Bg+2vARTy4+ckRBY0zVFRMTw9KlS1m+fDlffPEFn376Kffff3+x65Q1AFS1xJApDyELABHxAM8B5wCJwFgRSQyo9hdgt6p2BJ4EHnfLM4ChqtoN56Hx0/zW+ZeqngD0BE4RkXPK9E3KQdfGXXlqwFOESzhTl09l6m9TQ90lY0wpNG3alClTpjB58mRUtchhlgOHen7nnXcKtTF16lSGDx/OgAED6NSpky9MUlNT6dy5M+PGjaNr165s2rSJO+64g65du9KtWzdfO6rKjTfeSOfOnTnrrLPYsWOHr+22bdv67lROSUnxjTu0b98+Xz+TkpKYOXMmEyZM4ODBg/To0YNLLrmkXP9OwQwG178S0TwAAB6VSURBVAdYp6obAERkOjAcWOFXZzgwyX3/HjBZRERVl/jVWQ7EiEiUqh4A5gGoao6I/AwklOmblJOTW53MQ6c+xIRvJ/DE4idoFNOIYR2GhbpbxlQfk+IqqN3MY6revn178vPz2bFjB//973+LHGY5cKjnQD/99BO//fYbderUoXfv3gwZMoTGjRuzdu1aXn/9dfr27cvMmTNZunQpv/zyCxkZGfTu3Zv+/fuzcOFCVq9ezYoVK9i+fTuJiYlcddVVxfb5wQcfJC4ujmXLlgGwe/duRo4cyeTJk0scY6g0gjkE1ArY5Def5pYVWUdV84BMID6gzkjgZ1U95F8oIg2AocBXRX24iIwXkRQRSUlPTw+iu2U3pP0Q/t777wBM/G4i36R9Uymfa4ypGAsWLODSSy8FjhxmuTiDBg0iPj6emJgYRowYwYIFCwBo06YNffv29bU9duxYPB4PzZo14/TTT2fRokV88803vvKWLVty5plnlvh5X375JTfccINvvmHDhqX5ukGrlOGgRaQLzmGhwQHl4cDbwDMFexiBVHUKMAWcsYAquKs+lyZeSsbBDF757RVu//p2Xh78Mt2bdK+sjzem+jrGX+oVZcOGDXg8Hpo2bVrqNgKHjS+Yr1u3bpn6Fh4e7jt3kJ2dXaa2yiKYPYDNgP9TBxLcsiLruBv1OGCnO58AzALGqer6gPWmAGtV9alj73rF+2uvv3JBxws4mHeQG766gQ17iswoY0wVk56ezrXXXsuNN96IiBx1mOXihmYG+OKLL9i1axcHDx7kgw8+4JRTTjmizmmnncY777xDfn4+6enpfPPNN/Tp04f+/fv7yrdu3ep7vCM45wAWL14MwMyZM33lgwYN4rnnnvPN7969G4CIiIigH1BzLIIJgEVAJxFpJyKRwBhgdkCd2TgneQFGAXNVVd3DO3OACar6nf8KIvIQTlD8rSxfoCKJCBP7TWRAwgAyD2VyzZfXsG3/tlB3yxhThIITpV26dOGss85i8ODB3HfffcDRh1kOHOo5UJ8+fRg5ciRJSUmMHDmS5OQjBtTkggsuICkpie7du3PmmWfyz3/+k+bNm3PBBRfQqVMnEhMTGTduHP369fOtc9999/HXv/6V5ORkPB6Pr/yee+5h9+7ddO3ale7du/tCY/z48SQlJZX7SeCghoMWkXOBpwAP8KqqPiwiDwApqjpbRKJxrvDpCewCxqjqBhG5B7gLWOvX3GAgEuecwSqg4JzAZFX9T3H9KI/hoEvjYN5BrvniGpbsWEKHuA68fs7rxEVV0IkuY6qhmjgc9NSpU4s9QVxVHctw0EGdA1DVT4BPAsom+r3PBi4sYr2HgIeO0my1eSZjTHgMz575LFd8dgXr9qzjxq9uZMrgKcSEx5S8sjHGVFF2J3CQ4qLiePGsF2lRtwVL05dy+9e325ARxtRgV1xxRbX79X+sLACOQbO6zXhx0IvERcXxTdo33P/9/VSnJ6oZY4w/C4Bj1D6uPc8PdIaM+HD9hzz1c5W8gMkYY0pkAVAKSU2S+PeAfxMu4bz626u8sfyNUHfJGGOOmQVAKZ3a6lQeOOUBAP4v5f/4eMPHIe6RMcYcGwuAMhjaYSi3J98OwL0L7uW7zd+VsIYxpqIUDAfdvXt3evXqxffff19s/dTUVLp27Vpiu8HWq44sAMro8i6Xc2WXK8nTPG6ZfwvL0peFukvG1EoFw0H/8ssvPProo9x1112h7lKVZwFQDm456RaGdRjGwbyDXP/V9fye+Xuou2RMrZaVleUbSG3fvn0MHDiQXr160a1bNz788ENfvfz8fK6++mq6dOnC4MGDOXjwIACLFy+me/fudO/evdDQDKmpqZx22mn06tWr0F7G/PnzGTBgAKNGjeKEE07gkksu8V0h+MADD9C7d2+6du3K+PHjfeUDBgyg4MbWjIwM2rZtW+F/l0CVMhhcTSciTDp5EnsO7eGbtG+45otrmHbONJrVbRbqrhlT6bq93q1C2l12efF71wVDQWRnZ7N161bmzp0LQHR0NLNmzSI2NpaMjAz69u3LsGHOEO9r167l7bff5uWXX2b06NHMnDmTSy+9lCuvvJLJkyfTv39/7rjjDt9nNG3alC+++ILo6GjWrl3L2LFjfRvxJUuWsHz5clq2bMkpp5zCd999x6mnnsqNN97IxInOfbOXXXYZH3/8MUOHDq2IP9Exsz2AchIRFsG/Tv8XSU2S2Lp/K9d+eS2Zh6rGqIjG1AYFh4BWrVrFZ599xrhx41BVVJW7776bpKQkzjrrLDZv3sz27dsBaNeuHT169ADgpJNOIjU1lT179rBnzx769+8POBvtArm5uVx99dV069aNCy+8kBUrDj8WpU+fPiQkJBAWFkaPHj1ITU0FYN68efzpT3+iW7duzJ07l+XLl1fSX6RktgdQjmLCY3juzOe4/LPLWbdnHTfPvZmXBr1EdHh0qLtmTKUp6Zd6ZejXrx8ZGRmkp6fzySefkJ6ezuLFi4mIiKBt27a+IZijoqJ863g8Ht8hoKN58sknadasGb/88gter5fo6MP/tgPbysvLIzs7m+uvv56UlBRat27NpEmTfJ9dFYaEtj2ActYgugEvDXqJZnWa8fOOn7njmzvI8+aFulvG1CqrVq0iPz+f+Ph4MjMzadq0KREREcybN48//vij2HUbNGhAgwYNfA9/KRhGGiAzM5MWLVoQFhbGtGnTyM/PL7atgg1748aN2bdvX6GHwvsPCV3ah8WXlQVABWhetzkvDXqJuKg45m+az4M/PGhDRhhTwQrOAfTo0YOLLrqI119/HY/HwyWXXEJKSgrdunXjjTfe4IQTTiixrddee40bbriBHj16FPq3e/311/P666/TvXt3Vq1aVeKDYRo0aMDVV19N165d+fOf/0zv3r19y26//XZeeOEFevbs6Xs+cGULajjoqiJUw0GX1tIdS7n6f1eTnZ/N1d2u5uZeN4e6S8ZUiJo4HHR1dSzDQdseQAXq0bQHTwx4Ao94eHnZy7y58s2SVzLGmEpiAVDB+if05/6T7wfgsZ8eY9baWSHukTHGOCwAKsHwjsO59aRbAZj4/UQmfT+J7LzQPQjamIpQnQ4n11TH+t/AAqCSXNn1Sib2m0hkWCQz185k7JyxbMi0h8ybmiE6OpqdO3daCISQqrJz585Cl6aWJNhnAp8NPI3zTOD/qOpjAcujgDeAk4CdwEWqmioig4DHcJ4BnAPcoapz3XVOAqYCMTiPm/yrltCZ6nYSuCird63m9q9vJzUrlZjwGO7tey9DO1SNuwKNKa3c3FzS0tJCdj27cURHR5OQkEBERESh8qOdBC4xAETEA6wBBgFpwCJgrKqu8KtzPZCkqteKyBjgAlW9SER6AttVdYuIdAU+V9VW7jo/ATcDP+IEwDOq+mlxfakJAQCwP3c/D/7wIHM2zAHg/I7nc/ef7rZnDBtjKkRZrgLqA6xT1Q2qmgNMB4YH1BkOvO6+fw8YKCKiqktUdYtbvhyIEZEoEWkBxKrqD+6v/jeA80vxvaqluhF1efTUR7n/5PuJ8kTxwboPuHjOxazfsz7UXTPG1CLBBEArYJPffJpbVmQdVc0DMoH4gDojgZ9V9ZBbP62ENgEQkfEikiIiKenp6UF0t3oQEUZ0GsFbQ96iXVw71u1Zx9g5Y/lg3Qeh7poxppaolJPAItIFeBy45ljXVdUpqpqsqslNmjQp/86F2PENj2f6kOm+4aTv/e5e/rHgHxzIPRDqrhljarhgAmAz0NpvPsEtK7KOiIQDcTgngxGRBGAWME5V1/vVTyihzVqjTkQdHj71YR485UGiPdHMXj+bsXPGsnb32lB3zRhTgwUTAIuATiLSTkQigTHA7IA6s4HL3fejgLmqqiLSAJgDTFBV3/MSVXUrkCUifUVEgHHAh9Ry53c8n7eHvE2HuA5syNzAxXMuZtbaWXZpnTGmQpQYAO4x/RuBz4GVwAxVXS4iD4jIMLfaK0C8iKwDbgUmuOU3Ah2BiSKy1H01dZddD/wHWAesB4q9Aqi26NiwI28NeYvzO55Pdn42E7+fyN0L7rZDQsaYcmeDwVVhs9fP5qEfHuJg3kHaxrbliQFPcHzD40PdLWNMNWODwVVDwzoMY/qQ6XRs0JHUrFQunnMx7615zw4JGWPKhQVAFde+QXveGvIWIzqN4FD+Ie5feD8Tvp3A/tz9oe6aMaaaswCoBmLCY7j/5Pt55NRHiAmP4ZPfP2HMx2NYvWt1qLtmjKnGLACqkaEdhjL9vOl0atjJd0hoxuoZdkjIGFMqFgDVTPu49rx17luMOn4UOd4cHvzhQe785k725ewLddeMMdWMBUA1FB0ezX397uPx0x6nTngdPkv9jIs+voiVO1eGumvGmGrEAqAaO7f9ubxz3jt0btiZjXs3csknlzB91XQ7JGSMCYoFQDXXNq4tbw55k4s6X0SuN5eHf3yY276+jb05e0PdNWNMFWcBUANEeaK4p+89/N/p/0fdiLp88ccXjP5oNMt3Lg9114wxVZgFQA1ydtuzmXHeDE5sdCJp+9K47JPLeGvlW3ZIyBhTJAuAGua42OOYdu40xnQeQ643l0d/epRb599KVk5WqLtmjKliLABqoChPFP/o+w+eOP0J6kXU48uNXzL6o9H8lvFbqLtmjKlCLABqsMFtBzPjvBkkxieyed9mLvv0Mv674r92SMgYA1gA1HitY1sz7ZxpXHLiJeR583h80eP8bd7f2J29O9RdM8aEmAVALRDpiWRCnwk8OeBJ6kfUZ+6muQz9YCgzVs8g35sf6u4ZY0LEAqAWOavNWcwYOoM/tfgTmYcyefCHBxk7ZyxLdywNddeMMSFgAVDLJNRP4OVBL/PE6U/QvG5zVu5ayWWfXsY9C+4h42BGqLtnjKlEQQWAiJwtIqtFZJ2ITChieZSIvOMu/1FE2rrl8SIyT0T2icjkgHXGisgyEflVRD4Tkcbl8YVMyUSEwW0H8+HwD7m629VEhEXw4foPGTZrGG+ufJM8b16ou2iMqQQlBoCIeIDngHOARGCsiCQGVPsLsFtVOwJPAo+75dnAvcDtAW2GA08DZ6hqEvArzvODTSWqE1GHm3vdzAfDP+C0VqexN3cvj/30GBd+dCGLti0KdfeMMRUsmD2APsA6Vd2gqjnAdGB4QJ3hwOvu+/eAgSIiqrpfVRfgBIE/cV91RUSAWGBLab+EKZvjYo/juYHP8eyZz9KqXivW7VnHVZ9fxZ3f3Mn2/dtD3T1jTAUJJgBaAZv85tPcsiLrqGoekAnEH61BVc0FrgOW4Wz4E4FXiqorIuNFJEVEUtLT04PorikNEWFA6wF8eP6H3NDjBqI8UXz6+6cM+2AYr/32Grn5uaHuojGmnIXkJLCIROAEQE+gJc4hoLuKqquqU1Q1WVWTmzRpUom9rJ2iPFFc2/1aPjz/QwYeN5ADeQf49+J/M2L2CL7f8n2ou2eMKUfBBMBmoLXffIJbVmQd9/h+HLCzmDZ7AKjqenVuS50BnBxkn00laFWvFU+d8RQvnvUibWPbkpqVyjVfXMMt825hyz47WmdMTRBMACwCOolIOxGJBMYAswPqzAYud9+PAuZq8eMNbAYSRaTgJ/0gwB5nVQWd0uoU3h/2PrecdAsx4TF8ufFLhn8wnJd+eYlD+YdC3T1jTBlIMOPCiMi5wFOAB3hVVR8WkQeAFFWdLSLRwDScQzq7gDGqusFdNxXnJG8ksAcYrKorRORa4K9ALvAHcIWqFrfXQHJysqakpJTum5oy275/O08sfoJPf/8UgIR6CUzoM4HTW58e4p4ZY4ojIotVNfmI8uo0MJgFQNWwaNsiHvnxEdbtWQfA6Qmn8/fef6d1bOsS1jTGhMLRAsDuBDbHrHfz3swYOoO/9/479SLq8XXa1wz/cDjPLnmWg3kHQ909Y0yQLABMqUSERXBp4qV8dMFHDOswjFxvLlN+ncLwD4bzxR9f2JDTxlQDFgCmTBrHNObhUx9m2jnTOLHRiWzdv5Vb59/KNV9cw4bMDaHunjGmGBYAplz0aNqDt4e8zb197yU2MpaFWxcy8sOR/Dvl3+zP3R/q7hljimABYMqNJ8zD6M6j+fiCjxl1/CjyNZ/Xlr/G0FlDmbNhjh0WMqaKsQAw5a5hdEPu63cfbw95m6TGSaQfTGfCtxO48vMrWbN7Tai7Z4xxWQCYCtOlcRemnTuNB05+gEbRjVi8fTGjPxrNYz89RlZOVqi7Z0ytZwFgKlSYhHFBpwuYff5sLj7hYhTlzZVvMnTWUGatnUWu1waZMyZU7EYwU6lW71rNIz8+ws87fgagSUwTRnQawchOI2lRr0WIe2dMzWR3ApsqQ1WZ8/scpvw6hd8zfwecPYVTW53K6ONHc2qrU/GEeULcS2NqDgsAU+WoKou3L2bGmhl8+ceXvsNBzes2Z0SnEYzoOIJmdZuFuJfGVH8WAKZK25W9iw/Xfch7a95j496NAHjEw+kJpzO682j6texHmNgpK2NKwwLAVAte9fLTtp+YsXoG8zbOI0+dB9S3qteKUceP4vyO59M4pnGIe2lM9WIBYKqdjIMZzFo7i5lrZ7J5n/MMovCwcM5sfSajO4+mT/M+OI+UNsYUxwLAVFv53ny+3/I97655l6/TvsarXgDaxLbhwuMvZFiHYTSMbhjiXhpTdVkAmBph2/5tvr2C7Qe2A87IpIPaDGJ059H0atrL9gqMCWABYGqUPG8e36Z9y7tr3mXB5gUozv/H7ePaM7rzaM5rfx5xUXEh7qUxVYMFgKmxNu/bzMw1M5m1bhYZBzMAiPJE8ee2f2Z059EkNU6yvQJTq5UpAETkbOBpnGcC/0dVHwtYHgW8AZwE7AQuUtVUEYkH3gN6A1NV9Ua/dSKBycAAwAv8Q1VnFtcPCwBTnFxvLvM3zefd1e+ycOtCX/nxDY9n9PGjGdJ+CPUi64Wwh8aERqkDQEQ8wBpgEJAGLALGquoKvzrXA0mqeq2IjAEuUNWLRKQuzoPiuwJdAwLgfsCjqveISBjQSFUziuuLBYAJ1sasjby39j0+WPsBuw/tBiAmPIZz253LhZ0vpEt8lxD30JjKU5YA6AdMUtU/u/N3Aajqo351PnfrLBSRcGAb0ETdxkXkCiA5IAA2ASeoatBPC7EAMMcqJz+HrzZ+xYzVM0jZfvj/ncT4RC48/kLObXcudSLqhLCHxlS8sjwUvhWwyW8+zS0rso6q5gGZQHwxnWngvn1QRH4WkXdFpMh7/kVkvIikiEhKenp6EN015rBITyTntDuH185+jQ/P/5DLEi8jNjKWFTtXcP/C+znz3TOZ9P0kPkv9zHf+wJjaIjyEn5sAfK+qt4rIrcC/gMsCK6rqFGAKOHsAldpLU6O0j2vPnb3v5OaeN/PFH18wY/UMlqYvZebamcxcO9NXp3fz3iQ3Tya5WbLddWxqtGACYDPQ2m8+wS0rqk6aewgoDudk8NHsBA4A77vz7wJ/CabDxpRVdHg0QzsMZWiHoazZvYb5m+azaNsifkn/hQ2ZG9iQuYF3Vr8DQLu4dvRu1tsXChYIpiYJJgAWAZ1EpB3Ohn4McHFAndnA5cBCYBQwV4s5uaCqKiIf4VwBNBcYCKw4Wn1jKsrxDY/n+IbHMz5pPLn5uSzfuZxF2xaxaNsilqYv5ffM3/k983dmrJkBOIGQ3CzZCYRmyTSp0yTE38CY0gv2MtBzgadwLgN9VVUfFpEHgBRVnS0i0cA0nCt+dgFjVHWDu24qEAtEAnuAwaq6QkTauOs0ANKBK1V1Y3H9sJPApjIVBELK9hQWbVvEkh1LOJh3sFCdtrFt6d28twWCqdLsRjBjyijXm8vyDCcQUral8POOn4sMhOTmyfRu5hwyalqnaYh6a8xhFgDGlLNcby4rdq5g0bZFxQbCSc1O8u0h2ANuTChYABhTwXK9uazcudI5h7B9EUu2L+FA3oFCddrEtil0DsECwVQGCwBjKlmeN88JhO3OSeWft/98RCAcV/843xVGvZr2okXdFjZukSl3FgDGhFieN49Vu1b5rjL6ecfP7M8tfCN8w6iGJMYnkhifSJf4LiTGJ9K8bnMLBVMmFgDGVDEFgZCyLYVF2xexLH2Zb9wif42iG3Fi/Im+QOgS34VmdZpZKJigWQAYU8WpKlv3b2XFzhUs37ncN808lHlE3UbRjQrtJXSJ70LTOk0tFEyRLACMqYZUlS37t7A8wwmEglDIysk6om58dDxdGjuBkNgokS6Nu9hlqAawADCmxlBVNu/bXGgvYcXOFezN2XtE3cYxjQvtJSTGJ9rNarWQBYAxNZiqkrY3jeW7lrMiY4Vvb2Fv7pGh0DSm6eETze4eg41xVLNZABhTy3jVS9retEJ7CSt2rmBf7r4j6jatczgUEuolEBcVR2xkLLFRscRFxhEbFUtEWEQIvoUpDxYAxhi86mXT3k2HzynsckIh8HLUotQJr+MLhIKA8A8K/3n/ab2IenZyOsQsAIwxRfKql41ZG1m+czkrd64k/WA6WTlZZB3KIisni8xDmWTlZJGv+aVqP0zCnJAICIyCPYuipvUj6xMmYeRrPvmaj9frdaZazNRbwvKAdoJpw6tewiQMEcEjHuc9gifM40zFU3iZFC4TEcIIO7JMwnwvj3gKtekrC2ijZb2WpX56nQWAMabUVJX9ufvJzMkk61BWoWlBQPgHRkFZ5qHMI+5+NqXz/MDnOS3htFKte7QACNUTwYwx1YiIUC+yHvUi69GqXuATYYuX6809Ym/CPzSOFiaA88s6LMz3C7tg6v/+aHX8p56woyw7Wrnf5yhKvuajqr69goK9BFV3GUUv8y/zqhcv3iPLApd7i65XN6Juuf93tQAwxlSoiLAI4mPiiY856mPCTYgE81B4Y4wxNZAFgDHG1FJBBYCInC0iq0VknYhMKGJ5lIi84y7/UUTauuXxIjJPRPaJyOSjtD1bRH4ry5cwxhhz7EoMABHxAM8B5wCJwFgRSQyo9hdgt6p2BJ4EHnfLs4F7gduP0vYI4Mi7UowxxlS4YPYA+gDrVHWDquYA04HhAXWGA6+7798DBoqIqOp+VV2AEwSFiEg94FbgoVL33hhjTKkFEwCtgE1+82luWZF1VDUPyARKOuX/IPAEUOxFwiIyXkRSRCQlPT09iO4aY4wJRkhOAotID6CDqs4qqa6qTlHVZFVNbtLERjE0xpjyEkwAbAZa+80nuGVF1hGRcCAO2FlMm/2AZBFJBRYAx4vI/OC6bIwxpjwEcyPYIqCTiLTD2dCPAS4OqDMbuBxYCIwC5moxY0yo6gvACwDuFUMfq+qAkjqyePHiDBH5I4g+V2WNgYxQd6KKsL9FYfb3KMz+HoeV9W/RpqjCEgNAVfNE5Ebgc8ADvKqqy0XkASBFVWcDrwDTRGQdsAsnJABwf+XHApEicj4wWFVXlOYbqGq1PwYkIilFjclRG9nfojD7exRmf4/DKupvEdRQEKr6CfBJQNlEv/fZwIVHWbdtCW2nAl2D6YcxxpjyY3cCG2NMLWUBUPmmhLoDVYj9LQqzv0dh9vc4rEL+FtXqeQDGGGPKj+0BGGNMLWUBYIwxtZQFQCUQkdbuqKgrRGS5iPw11H2qCkTEIyJLROTjUPcl1ESkgYi8JyKrRGSliPQLdZ9CRURucf+d/CYib4tIdKj7VJlE5FUR2eE/SrKINBKRL0RkrTttWB6fZQFQOfKA21Q1EegL3FDEiKq10V+BlaHuRBXxNPCZqp4AdKeW/l1EpBVwM5Csql1x7j0aU/xaNc5U4OyAsgnAV6raCfjKnS8zC4BKoKpbVfVn9/1enH/cx/Zg1RpGRBKAIcB/Qt2XUBOROKA/zg2VqGqOqu4Jba9CKhyIcYeVqQNsCXF/KpWqfoNzQ60//xGXXwfOL4/PsgCoZO7QFz2BH0Pbk5B7CrgT8Ia6I1VAOyAdeM09JPYfESn/J4BXA6q6GfgXsBHYCmSq6v9C26sqoZmqbnXfbwOalUejFgCVyH0Gwkzgb6qaFer+hIqInAfsUNXFoe5LFREO9AJeUNWewH7KaRe/unGPbQ/HCcWWQF0RuTS0vapa3HHWyuX6fQuASiIiETgb/zdV9f1Q9yfETgGGueNETQfOFJH/hrZLIZUGpKlqwV7heziBUBudBfyuqumqmgu8D5wc4j5VBdtFpAWAO91RHo1aAFQCERGc47srVfXfoe5PqKnqXaqa4I4TNQZn9Nha+ytPVbcBm0Sks1s0ECjVgIk1wEagr4jUcf/dDKSWnhAPUDDiMu70w/Jo1AKgcpwCXIbzS3ep+zo31J0yVcpNwJsi8ivQA3gkxP0JCXcv6D3gZ2AZzjaqVg0JISJv4wyt31lE0kTkL8BjwCARWYuzl/RYuXyWDQVhjDG1k+0BGGNMLWUBYIwxtZQFgDHG1FIWAMYYU0tZABhjTC1lAWCMMbWUBYAxxtRS/x9mHxFskQWtgAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBeMYwpMOPyI",
        "colab_type": "text"
      },
      "source": [
        "# Translation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ad9Fn5HrOO6i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def translate(sentence, encoder, decoder):\n",
        "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_length_inp,\n",
        "                                                         padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  result = ''\n",
        "\n",
        "  hidden = [tf.zeros((1, units))]\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "  for t in range(max_length_targ):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                         dec_hidden,\n",
        "                                                         enc_out)\n",
        "\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "    result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "    # until the predicted word is <end>.\n",
        "    if targ_lang.index_word[predicted_id] == '<end>':\n",
        "      return result, sentence\n",
        "\n",
        "    # the predicted ID is fed back into the model, no teacher forcing.\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  return result, sentence"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmPB_EoAWxKP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "438316ba-a27a-4240-c2fb-4d458dfc29ee"
      },
      "source": [
        "result, sentence = translate(u'esta es mi vida.', encoder_bah, decoder_bah)\n",
        "print('Input: %s' % (sentence))\n",
        "print('Predicted translation: {}'.format(result))"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> esta es mi vida . <end>\n",
            "Predicted translation: this is my life . <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrB48Fwk7XW8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "50c1e280-b4e5-4b45-d780-b4cb6fa95a1b"
      },
      "source": [
        "result, sentence = translate(u'¿todavia estan en casa?', encoder_bah, decoder_bah)\n",
        "print('Input: %s' % (sentence))\n",
        "print('Predicted translation: {}'.format(result))"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> ¿ todavia estan en casa ? <end>\n",
            "Predicted translation: are you still home ? <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLZcz8TbR09_",
        "colab_type": "text"
      },
      "source": [
        "# Next Steps\n",
        "\n",
        "\n",
        "*   Training on larger dataset\n",
        "*   Model tuning\n",
        "*   Try out other attention scores such as multiplicative\n",
        "*   Train on other seq2seq tasks\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}